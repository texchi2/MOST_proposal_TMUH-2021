Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Ching2018,
abstract = {Artificial neural networks (ANN) are computing architectures with many interconnections of simple neural-inspired computing elements, and have been applied to biomedical fields such as imaging analysis and diagnosis. We have developed a new ANN framework called Cox-nnet to predict patient prognosis from high throughput transcriptomics data. In 10 TCGA RNA-Seq data sets, Cox-nnet achieves the same or better predictive accuracy compared to other methods, including Cox-proportional hazards regression (with LASSO, ridge, and mimimax concave penalty), Random Forests Survival and CoxBoost. Cox-nnet also reveals richer biological information, at both the pathway and gene levels. The outputs from the hidden layer node provide an alternative approach for survival-sensitive dimension reduction. In summary, we have developed a new method for accurate and efficient prognosis prediction on high throughput data, with functional biological insights. The source code is freely available at https://github.com/lanagarmire/cox-nnet.},
annote = {https://github.com/lanagarmire/Cox-nnet-v2.0
Cox-nnet 2.0},
author = {Ching, Travers and Zhu, Xun and Garmire, Lana X.},
doi = {10.1371/journal.pcbi.1006076},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Ching, Zhu, Garmire - 2018 - Cox-nnet An artificial neural network method for prognosis prediction of high-throughput omics data(2).pdf:pdf},
issn = {15537358},
journal = {PLoS Computational Biology},
keywords = {Cox-nnet},
mendeley-tags = {Cox-nnet},
month = {apr},
number = {4},
pmid = {29634719},
publisher = {Public Library of Science},
title = {{Cox-nnet: An artificial neural network method for prognosis prediction of high-throughput omics data}},
volume = {14},
year = {2018}
}
@article{Hao2020,
abstract = {The integration of multi-modal data, such as histopathological images and genomic data, is essential for understanding cancer heterogeneity and complexity for personalized treatments, as well as for enhancing survival predictions in cancer study. Histopathology, as a clinical gold-standard tool for diagnosis and prognosis in cancers, allows clinicians to make precise decisions on therapies, whereas high-throughput genomic data have been investigated to dissect the genetic mechanisms of cancers. We propose a biologically interpretable deep learning model (PAGE-Net) that integrates histopathological images and genomic data, not only to improve survival prediction, but also to identify genetic and histopathological patterns that cause different survival rates in patients. PAGE-Net consists of pathology/genome/demography-specific layers, each of which provides comprehensive biological interpretation. In particular, we propose a novel patch-wise texture-based convolutional neural network, with a patch aggregation strategy, to extract global survival-discriminative features, without manual annotation for the pathology-specific layers. We adapted the pathway-based sparse deep neural network, named Cox-PASNet, for the genome-specific layers. The proposed deep learning model was assessed with the histopathological images and the gene expression data of Glioblastoma Multiforme (GBM) at The Cancer Genome Atlas (TCGA) and The Cancer Imaging Archive (TCIA). PAGE-Net achieved a C-index of 0.702, which is higher than the results achieved with only histopathological images (0.509) and Cox-PASNet (0.640). More importantly, PAGE-Net can simultaneously identify histopathological and genomic prognostic factors associated with patients survivals. The source code of PAGE-Net is publicly available at https://github.com/DataX-JieHao/PAGE-Net.},
annote = {https://github.com/DataX-JieHao/PAGE-Net

The proposed deep learning model was assessed with the histopathological images and the gene expression data of Glioblastoma Multiforme (GBM) at The Cancer Genome Atlas (TCGA) and The Cancer Imaging Archive (TCIA). PAGE-Net achieved a C-index of 0.702, which is higher than the results achieved with only histopathological images (0.509) and Cox-PASNet (0.640)},
author = {Hao, Jie and Kosaraju, Sai Chandra and Tsaku, Nelson Zange and Song, Dae Hyun and Kang, Mingon},
file = {:Users/texchi/Downloads/9789811215636{\_}0032.pdf:pdf},
issn = {2335-6936 (Electronic)},
journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
language = {eng},
pages = {355--366},
pmid = {31797610},
title = {{PAGE-Net: Interpretable and Integrative Deep Learning for Survival Analysis Using Histopathological Images and Genomic Data.}},
volume = {25},
year = {2020}
}
@article{Rajkomar2018,
abstract = {Predictive modeling with electronic health record (EHR) data is anticipated to drive personalized medicine and improve healthcare quality. Constructing predictive statistical models typically requires extraction of curated predictor variables from normalized EHR data, a labor-intensive process that discards the vast majority of information in each patient's record. We propose a representation of patients' entire raw EHR records based on the Fast Healthcare Interoperability Resources (FHIR) format. We demonstrate that deep learning methods using this representation are capable of accurately predicting multiple medical events from multiple centers without site-specific data harmonization. We validated our approach using de-identified EHR data from two US academic medical centers with 216,221 adult patients hospitalized for at least 24 h. In the sequential format we propose, this volume of EHR data unrolled into a total of 46,864,534,945 data points, including clinical notes. Deep learning models achieved high accuracy for tasks such as predicting: In-hospital mortality (area under the receiver operator curve [AUROC] across sites 0.93-0.94), 30-day unplanned readmission (AUROC 0.75-0.76), prolonged length of stay (AUROC 0.85-0.86), and all of a patient's final discharge diagnoses (frequency-weighted AUROC 0.90). These models outperformed traditional, clinically-used predictive models in all cases. We believe that this approach can be used to create accurate and scalable predictions for a variety of clinical scenarios. In a case study of a particular prediction, we demonstrate that neural networks can be used to identify relevant information from the patient's chart.},
annote = {https://github.com/google/fhir},
archivePrefix = {arXiv},
arxivId = {1801.07860},
author = {Rajkomar, Alvin and Oren, Eyal and Chen, Kai and Dai, Andrew M. and Hajaj, Nissan and Hardt, Michaela and Liu, Peter J. and Liu, Xiaobing and Marcus, Jake and Sun, Mimi and Sundberg, Patrik and Yee, Hector and Zhang, Kun and Zhang, Yi and Flores, Gerardo and Duggan, Gavin E. and Irvine, Jamie and Le, Quoc and Litsch, Kurt and Mossin, Alexander and Tansuwan, Justin and Wang, De and Wexler, James and Wilson, Jimbo and Ludwig, Dana and Volchenboum, Samuel L. and Chou, Katherine and Pearson, Michael and Madabushi, Srinivasan and Shah, Nigam H. and Butte, Atul J. and Howell, Michael D. and Cui, Claire and Corrado, Greg S. and Dean, Jeffrey},
doi = {10.1038/s41746-018-0029-1},
eprint = {1801.07860},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Rajkomar et al. - 2018 - Scalable and accurate deep learning with electronic health records.pdf:pdf},
issn = {23318422},
journal = {npj Digital Med},
keywords = {FHIR,Machine learning,Medical research},
mendeley-tags = {FHIR},
month = {dec},
number = {1},
pages = {18},
publisher = {Nature Publishing Group},
title = {{Scalable and accurate deep learning with electronic health records}},
url = {http://www.nature.com/articles/s41746-018-0029-1},
volume = {1},
year = {2018}
}
@article{Wang2020a,
abstract = {With the development of the Internet, more and more creators publish articles on social media. How to automatically filter high quality content from a large number of multimedia articles is one of the core functions of information recommendation, search engine, and other systems. However, existing approaches typically suffer from two limitations: (1) They usually model content as word sequences, which ignores the semantics provided by non-consecutive phrases, long-distance word dependency, and visual information. (2) They rely on a large amount of manually annotated data to train a quality assessment model while users may only provide labels of interest in a single class for a small number of samples in reality. To address these limitations, we propose a Multimodal Graph Convolutional Networks (MGCN) to model the semantic representations in a unified framework for High Quality Content Recognition. Instead of viewing text content as word sequences, we convert them into graphs, which can model non-consecutive phrases and long-distance word dependency for better obtaining the composition of semantics. Besides, visual content is also modeled into the graphs to provide complementary semantics. A well-designed graph convolutional network is proposed to capture the semantic representations based on these graphs. Furthermore, we employ a non-negative risk estimator for high quality content recognition and the loss is back-propagated for model learning. Experiments on real datasets validate the effectiveness of our approach.},
author = {Wang, Jinguang and Hu, Jun and Qian, Shengsheng and Fang, Quan and Xu, Changsheng},
doi = {10.1016/j.neucom.2020.04.145},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Wang et al. - 2020 - Multimodal graph convolutional networks for high quality content recognition.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Graph convolutional networks,High quality content recognition,Positive unlabeled learning},
pages = {42--51},
publisher = {Elsevier B.V.},
title = {{Multimodal graph convolutional networks for high quality content recognition}},
url = {https://doi.org/10.1016/j.neucom.2020.04.145},
volume = {412},
year = {2020}
}
@misc{Herrmann2020,
abstract = {Multi-omics data, that is, datasets containing different types of high-dimensional molecular variables (often in addition to classical clinical variables), are increasingly generated for the investigation of various diseases. Nevertheless, questions remain regarding the usefulness of multi-omics data for the prediction of disease outcomes such as survival time. It is also unclear which methods are most appropriate to derive such prediction models. We aim to give some answers to these questions by means of a large-scale benchmark study using real data. Different prediction methods from machine learning and statistics were applied on 18 multi-omics cancer datasets from the database "The Cancer Genome Atlas", containing from 35 to 1,000 observations and from 60,000 to 100,000 variables. The considered outcome was the (censored) survival time. Twelve methods based on boosting, penalized regression and random forest were compared, comprising both methods that do and that do not take the group structure of the omics variables into account. The Kaplan-Meier estimate and a Cox model using only clinical variables were used as reference methods. The methods were compared using several repetitions of 5-fold cross-validation. Uno's C-index and the integrated Brier-score served as performance metrics. The results show that, although multi-omics data can improve the prediction performance, this is not generally the case. Only the method block forest slightly outperformed the Cox model on average over all datasets. Taking into account the multi-omics structure improves the predictive performance and protects variables in low-dimensional groups—especially clinical variables—from not being included in the model. All analyses are reproducible using freely available R code.},
annote = {Key Points
For the collection of the datasets used in this study, the standard Cox model only using clinical variables is very competitive compared with complex methods using multi-omics data. Among the investigated complex methods, only block forest outperforms the Cox model on average over all datasets, and the difference is not statistically significant.
If multi-omics data is used, its structure should be used as well: on average it increases the predictive performance and prevents low-dimensional feature groups from being discounted.
Favoring clinical variables over molecular data increases the prediction performance of the investigated methods on average.
In general, the findings indicate that assessing and comparing prediction methods should be based on a large number of datasets to reach robust conclusions.
Aside from the main results of the study, we also observed that using multi-omics data can improve the performance of prediction methods for particular datasets, but the average performance was not improved for the data investigated in our study.



==
our study does not include deep learning approaches. 
neutral comparison study
 26 cancer types -{\textgreater} 18 usable cancer datasets

it should also be easy to compare methods proposed later without re-running the full experiment and without too much programming effort. For this reason, we use the R package mlr [31], which offers a unified framework for benchmark experiments and makes them easily extendable and reproducible.
==
https://github.com/HerrMo/multi-omics{\_}benchmark{\_}study},
archivePrefix = {arXiv},
arxivId = {2003.03621},
author = {Herrmann, Moritz and Probst, Philipp and Hornung, Roman and Jurinovic, Vindi and Boulesteix, Anne Laure},
booktitle = {arXiv},
doi = {10.1093/bib/bbaa167},
eprint = {2003.03621},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Herrmann et al. - 2020 - Large-scale benchmark study of survival prediction methods using multi-omics data.pdf:pdf},
issn = {23318422},
keywords = {Benchmark,Machine learning,Multi-omics data,Prediction models,Statistics,Survival analysis,multi-omics,survival},
mendeley-tags = {multi-omics,survival},
month = {aug},
title = {{Large-scale benchmark study of survival prediction methods using multi-omics data}},
url = {https://academic.oup.com/bib/advance-article/doi/10.1093/bib/bbaa167/5895463},
year = {2020}
}
@article{Ching2018a,
abstract = {Deep learning, which describes a class of machine learning algorithms, has recently showed impressive results across a variety of domains. Biology and medicine are data rich, but the data are complex and often ill-understood. Problems of this nature may be particularly well-suited to deep learning techniques. We examine applications of deep learning to a variety of biomedical problems—patient classification, fundamental biological processes, and treatment of patients—and discuss whether deep learning will transform these tasks or if the biomedical sphere poses unique challenges. We find that deep learning has yet to revolutionize or definitively resolve any of these problems, but promising advances have been made on the prior state of the art. Even when improvement over a previous baseline has been modest, we have seen signs that deep learning methods may speed or aid human investigation. More work is needed to address concerns related to interpretability and how to best model each problem. Furthermore, the limited amount of labeled data for training presents problems in some domains, as do legal and privacy constraints on work with sensitive health records. Nonetheless, we foresee deep learning powering changes at both bench and bedside with the potential to transform several areas of biology and medicine.},
annote = {https://github.com/greenelab/deep-review},
author = {Ching, Travers and Himmelstein, Daniel S. and Beaulieu-Jones, Brett K. and Kalinin, Alexandr A. and Do, Brian T. and Way, Gregory P. and Ferrero, Enrico and Agapow, Paul Michael and Zietz, Michael and Hoffman, Michael M. and Xie, Wei and Rosen, Gail L. and Lengerich, Benjamin J. and Israeli, Johnny and Lanchantin, Jack and Woloszynek, Stephen and Carpenter, Anne E. and Shrikumar, Avanti and Xu, Jinbo and Cofer, Evan M. and Lavender, Christopher A. and Turaga, Srinivas C. and Alexandari, Amr M. and Lu, Zhiyong and Harris, David J. and DeCaprio, Dave and Qi, Yanjun and Kundaje, Anshul and Peng, Yifan and Wiley, Laura K. and Segler, Marwin H.S. and Boca, Simina M. and Swamidass, S. Joshua and Huang, Austin and Gitter, Anthony and Greene, Casey S.},
doi = {10.1098/rsif.2017.0387},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Ching et al. - 2018 - Opportunities and obstacles for deep learning in biology and medicine.pdf:pdf},
isbn = {0000000305396},
issn = {1742-5662},
journal = {Journal of The Royal Society Interface},
number = {141},
title = {{Opportunities and obstacles for deep learning in biology and medicine}},
url = {https://royalsocietypublishing.org/doi/10.1098/rsif.2017.0387},
volume = {15},
year = {2018}
}
@phdthesis{Rietschel2018,
abstract = {Survival analysis has attracted the development of new deep learning models, most notably the recent state-of-the-art model DeepHit for competing risks. However, in real-world medical settings with many features and insufficient data, deep learning models can suffer from severe performance deficits. In this dissertation, we propose robust changes to DeepHit's architecture and training procedure to counter this problem. Furthermore, we develop several methods to improve DeepHit's performance through novel approaches to automatic feature selection in deep survival analysis. We propose both filter and hybrid methods for hard feature selection, as well as neural network architecture adaptations that achieve soft feature selection. Despite only sparse literature around feature selection for deep neural networks, and little previous evidence for its benefits, our experiments on two medical datasets demonstrate that substantial performance improvements against the original DeepHit model are achievable.},
annote = {2021 https://hpc.nih.gov/apps/DeepHit.html},
author = {Rietschel, Carl},
booktitle = {University of Oxford},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Rietschel - 2018 - Automated feature selection for survival analysis with deep learning.pdf:pdf},
keywords = {DeepHit},
mendeley-tags = {DeepHit},
number = {WP -},
school = {University of Oxford},
title = {{Automated feature selection for survival analysis with deep learning}},
type = {Thesis},
url = {https://ora.ox.ac.uk/objects/uuid:e63f1610-11bd-46f0-af14-b310b4bea048},
year = {2018}
}
@article{Wang2020,
abstract = {BACKGROUND AND OBJECTIVE: Cancer, as the most challenging part in the human disease history, has always been one of the main threats to human life and health. The high mortality of cancer is largely due to the complexity of cancer and the significant differences in clinical outcomes. Therefore, it will be significant to improve accuracy of cancer survival prediction, which has become one of the main fields of cancer research. Many calculation models for cancer survival prediction have been proposed at present, but most of them generate prediction models only by using single genomic data or clinical data. Multiple genomic data and clinical data have not been integrated yet to take a comprehensive consideration of cancers and predict their survival. METHOD: In order to effectively integrate multiple genomic data (including genetic expression, copy number alteration, DNA methylation and exon expression) and clinical data and apply them to predictive studies on cancer survival, similar network fusion algorithm (SNF) was proposed in this paper to integrate multiple genomic data and clinical data so as to generate sample similarity matrix, min-redundancy and max-relevance algorithm (mRMR) was used to conduct feature selection of multiple genomic data and clinical data of cancer samples and generate sample feature matrix, and finally two matrixes were used for semi-supervised training through graph convolutional network (GCN) so as to obtain a cancer survival prediction method integrating multiple genomic data and clinical data based on graph convolutional network (GCGCN). RESULT: Performance indexes of GCGCN model indicate that both multiple genomic data and clinical data play significant roles in the accurate survival time prediction of cancer patients. It is compared with existing survival prediction methods, and results show that cancer survival prediction method GCGCN which integrates multiple genomic data and clinical data has obviously superior prediction effect than existing survival prediction methods. CONCLUSION: All study results in this paper have verified effectiveness and superiority of GCGCN in the aspect of cancer survival prediction.},
author = {Wang, Chunyu and Guo, Junling and Zhao, Ning and Liu, Yang and Liu, Xiaoyan and Liu, Guojun and Guo, Maozu},
doi = {10.1109/TNB.2019.2936398},
file = {:Users/texchi/Downloads/wang2019.pdf:pdf},
issn = {1558-2639 (Electronic)},
journal = {IEEE transactions on nanobioscience},
keywords = {Algorithms,CNN,Computer,GCGCN,GCN,Genomics,Humans,Models,Neoplasms,Neural Networks,Prognosis,Statistical,Survival Analysis,diagnosis,genetics,graph,methods,mortality,survival},
language = {eng},
mendeley-tags = {CNN,GCGCN,GCN,graph,survival},
month = {jan},
number = {1},
pages = {117--126},
pmid = {31443039},
title = {{A Cancer Survival Prediction Method Based on Graph Convolutional Network}},
url = {https://ieeexplore.ieee.org/document/8809103/figures{\#}figures},
volume = {19},
year = {2020}
}
@article{Lopez2020a,
abstract = {Generative models provide a well-established statistical framework for evaluating uncertainty and deriving conclusions from large data sets especially in the presence of noise, sparsity, and bias. Initially developed for computer vision and natural language processing, these models have been shown to effectively summarize the complexity that underlies many types of data and enable a range of applications including supervised learning tasks, such as assigning labels to images; unsupervised learning tasks, such as dimensionality reduction; and out-of-sample generation, such as de novo image synthesis. With this early success, the power of generative models is now being increasingly leveraged in molecular biology, with applications ranging from designing new molecules with properties of interest to identifying deleterious mutations in our genomes and to dissecting transcriptional variability between single cells. In this review, we provide a brief overview of the technical notions behind generative models and their implementation with deep learning techniques. We then describe several different ways in which these models can be utilized in practice, using several recent applications in molecular biology as examples.},
author = {Lopez, Romain and Gayoso, Adam and Yosef, Nir},
doi = {10.15252/msb.20199198},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Lopez, Gayoso, Yosef - 2020 - Enhancing scientific discoveries in molecular biology with deep generative models.pdf:pdf},
issn = {1744-4292},
journal = {Molecular Systems Biology},
keywords = {deep generative models,molecular biology,neural networks},
number = {9},
pages = {e9198},
pmid = {32975352},
publisher = {European Molecular Biology Organization},
title = {{Enhancing scientific discoveries in molecular biology with deep generative models}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/32975352 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC7517326},
volume = {16},
year = {2020}
}
@article{Johnson2016,
abstract = {MIMIC-III (Medical Information Mart for Intensive Care) is a large, single-center database comprising information relating to patients admitted to critical care units at a large tertiary care hospital. Data includes vital signs, medications, laboratory measurements, observations and notes charted by care providers, fluid balance, procedure codes, diagnostic codes, imaging reports, hospital length of stay, survival data, and more. The database supports applications including academic and industrial research, quality improvement initiatives, and higher education coursework.},
author = {Johnson, Alistair E.W. and Pollard, Tom J. and Shen, Lu and Lehman, Li Wei H. and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and {Anthony Celi}, Leo and Mark, Roger G.},
doi = {10.1038/sdata.2016.35},
issn = {20524463},
journal = {Scientific Data},
keywords = {deep learning},
mendeley-tags = {deep learning},
month = {dec},
number = {1},
pages = {160035},
pmid = {27219127},
title = {{MIMIC-III, a freely accessible critical care database}},
url = {http://www.nature.com/articles/sdata201635},
volume = {3},
year = {2016}
}
@article{Wei2019,
abstract = {PubTator Central (https://www.ncbi.nlm.nih.gov/research/pubtator/) is a web service for viewing and retrieving bioconcept annotations in full text biomedical articles. PubTator Central (PTC) provides automated annotations from state-of-the-art text mining systems for genes/proteins, genetic variants, diseases, chemicals, species and cell lines, all available for immediate download. PTC annotates PubMed (29 million abstracts) and the PMC Text Mining subset (3 million full text articles). The new PTC web interface allows users to build full text document collections and visualize concept annotations in each document. Annotations are downloadable in multiple formats (XML, JSON and tab delimited) via the online interface, a RESTful web service and bulk FTP. Improved concept identification systems and a new disambiguation module based on deep learning increase annotation accuracy, and the new server-side architecture is significantly faster. PTC is synchronized with PubMed and PubMed Central, with new articles added daily. The original PubTator service has served annotated abstracts for ∼300 million requests, enabling third-party research in use cases such as biocuration support, gene prioritization, genetic disease analysis, and literature-based knowledge discovery. We demonstrate the full text results in PTC significantly increase biomedical concept coverage and anticipate this expansion will both enhance existing downstream applications and enable new use cases.},
author = {Wei, Chih Hsuan and Allot, Alexis and Leaman, Robert and Lu, Zhiyong},
doi = {10.1093/nar/gkz389},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Wei et al. - 2019 - PubTator central automated concept annotation for biomedical full text articles.pdf:pdf},
issn = {13624962},
journal = {Nucleic Acids Research},
keywords = {cell lines,deep learning,genes,genetic disorder,genetics,mining,national library of medicine (u.s.),united states national institutes of health,xml},
month = {jul},
number = {W1},
pages = {W587--W593},
pmid = {31114887},
publisher = {Oxford Academic},
title = {{PubTator central: automated concept annotation for biomedical full text articles}},
url = {https://academic.oup.com/nar/article/47/W1/W587/5494727},
volume = {47},
year = {2019}
}
@article{Tranchevent2019,
abstract = {Background The availability of high-throughput omics datasets from large patient cohorts has allowed the development of methods that aim at predicting patient clinical outcomes, such as survival and disease recurrence. Such methods are also important to better understand the biological mechanisms underlying disease etiology and development, as well as treatment responses. Recently, different predictive models, relying on distinct algorithms (including Support Vector Machines and Random Forests) have been investigated. In this context, deep learning strategies are of special interest due to their demonstrated superior performance over a wide range of problems and datasets. One of the main challenges of such strategies is the “small n large p” problem. Indeed, omics datasets typically consist of small numbers of samples and large numbers of features relative to typical deep learning datasets. Neural networks usually tackle this problem through feature selection or by including additional constraints during the learning process. Methods We propose to tackle this problem with a novel strategy that relies on a graph-based method for feature extraction, coupled with a deep neural network for clinical outcome prediction. The omics data are first represented as graphs whose nodes represent patients, and edges represent correlations between the patients' omics profiles. Topological features, such as centralities, are then extracted from these graphs for every node. Lastly, these features are used as input to train and test various classifiers. Results We apply this strategy to four neuroblastoma datasets and observe that models based on neural networks are more accurate than state of the art models (DNN: 85{\%}-87{\%}, SVM/RF: 75{\%}-82{\%}). We explore how different parameters and configurations are selected in order to overcome the effects of the small data problem as well as the curse of dimensionality. Conclusions Our results indicate that the deep neural networks capture complex features in the data that help predicting patient clinical outcomes.},
annote = {Implementation
The data processing was performed in python (using packages numpy and pandas). The graph inference and topological analyses were performed in python and C++ (using packages networkx, scipy, igraph, graph-tool and SNFtool). The SVM and RF classifiers were built in R (with packages randomForest and e1071). The DNN classifiers were built in python (with TensorFlow) using the DNNClassifier estimator. Training was performed using only CPU cores. GEDFN was run in Python using the implementation provided by the authors. Figures and statistical tests were prepared in R.


This article has been published as part of BMC Medical Genomics, Volume 12 Supplement 8, 2019: 18th International Conference on Bioinformatics. The full contents of the supplement are available at https://bmcmedgenomics.biomedcentral.com/articles/supplements/volume-12-supplement-8.},
author = {Tranchevent, L{\'{e}}on-charles and Azuaje, Francisco and Rajapakse, Jagath C},
doi = {10.1186/s12920-019-0628-y},
file = {:Users/texchi/Downloads/Tranchevent2019{\_}Article{\_}ADeepNeuralNetworkApproachToPr.pdf:pdf},
issn = {1755-8794},
journal = {BMC Medical Genomics},
keywords = {C++,Clinical outcome prediction,DNN,Deep learning,Deep neural network,Disease prediction,Graph topology,Machine learning,Network-based methods,and,asjagath,bioinformatics research center,clinical outcome prediction,correspondence,deep learning,deep neural network,disease prediction,edu,graph topology,machine learning,network-based methods,ntu,school of computer science,sg,survival},
mendeley-tags = {C++,DNN,deep learning,survival},
pages = {1--11},
publisher = {BMC Medical Genomics},
title = {{A deep neural network approach to predicting clinical outcomes of neuroblastoma patients}},
url = {http://dx.doi.org/10.1186/s12920-019-0628-y},
volume = {12},
year = {2019}
}
@misc{Grattarola2020,
abstract = {In this paper we present Spektral, an open-source Python library for building graph neural networks with TensorFlow and the Keras application programming interface. Spektral implements a large set of methods for deep learning on graphs, including message-passing and pooling operators, as well as utilities for processing graphs and loading popular benchmark datasets. The purpose of this library is to provide the essential building blocks for creating graph neural networks, focusing on the guiding principles of user-friendliness and quick prototyping on which Keras is based. Spektral is, therefore, suitable for absolute beginners and expert deep learning practitioners alike. In this work, we present an overview of Spektral's features and report the performance of the methods implemented by the library in scenarios of node classification, graph classification, and graph regression.},
archivePrefix = {arXiv},
arxivId = {cs.LG/2006.12138},
author = {Grattarola, Daniele and Alippi, Cesare},
eprint = {2006.12138},
keywords = {GNN,keras,tensorflow},
mendeley-tags = {GNN,keras,tensorflow},
primaryClass = {cs.LG},
title = {{Graph Neural Networks in TensorFlow and Keras with Spektral}},
url = {https://github.com/danielegrattarola/spektral},
year = {2020}
}
@article{Fortelny2020,
abstract = {Deep learning has emerged as a versatile approach for predicting complex biological phenomena. However, its utility for biological discovery has so far been limited, given that generic deep neural networks provide little insight into the biological mechanisms that underlie a successful prediction. Here we demonstrate deep learning on biological networks, where every node has a molecular equivalent, such as a protein or gene, and every edge has a mechanistic interpretation, such as a regulatory interaction along a signaling pathway.},
annote = {Availability of data and materials
All datasets are openly available from public databases. The TCR dataset [49] was downloaded from GEO (GSE137554). The HCA dataset [50] was downloaded from the “Census of Immune Cells” that is part of the Human Cell Atlas (https://preview.data.humancellatlas.org/), as of 31 July 2018. The LCH dataset [51] was downloaded from GEO (GSE133704). The AML dataset [52] was downloaded from GEO (GSE116256). The glioblastoma dataset [53] was downloaded from GEO (GSE131928). The source code to train and analyze KPNNs (in Python and R) is available under the GNU General Public License v3.0 as a GitHub repository [125] and in archived form in Zenodo [126].

==
https://zenodo.org/record/3697744{\#}.X8Ouey0RoUQ
https://github.com/epigen/KPNN
https://github.com/hussius/deeplearning-biology},
author = {Fortelny, Nikolaus and Bock, Christoph},
doi = {10.1186/s13059-020-02100-5},
file = {:Users/texchi/Downloads/s13059-020-02100-5.pdf:pdf},
issn = {1474-760X},
journal = {Genome Biology},
keywords = {GCN,Interpretable deep learning,KPNNs,acyclic graph,single-cell RNA-seq,tensorflow},
mendeley-tags = {GCN,Interpretable deep learning,KPNNs,acyclic graph,single-cell RNA-seq,tensorflow},
number = {1},
pages = {190},
title = {{Knowledge-primed neural networks enable biologically interpretable deep learning on single-cell sequencing data}},
url = {https://doi.org/10.1186/s13059-020-02100-5},
volume = {21},
year = {2020}
}
@article{Rampasek2016,
author = {Rampasek, Ladislav and Goldenberg, Anna},
doi = {10.1016/j.cels.2016.01.009},
file = {:Users/texchi/Downloads/PIIS2405471216000107.pdf:pdf},
issn = {2405-4712},
journal = {Cell Systems},
keywords = {Tensorflow,deep learning},
mendeley-tags = {Tensorflow,deep learning},
number = {1},
pages = {12--14},
publisher = {Elsevier Inc.},
title = {{TensorFlow : Biology ' s Gateway to Deep Learning ?}},
url = {http://dx.doi.org/10.1016/j.cels.2016.01.009},
volume = {2},
year = {2016}
}
@inproceedings{Gao2020a,
abstract = {Predicting the survival of cancer patients holds significant meaning for public health, and has attracted increasing attention in medical information communities. In this study, we propose a novel framework for cancer survival prediction named Multimodal Graph Neural Network (MGNN), which explores the features of real-world multimodual data such as gene expression, copy number alteration and clinical data in a unified framework. In order to explore the inherent relation, we first construct the bipartite graphs between patients and multimodal data. Subsequently, graph neural network is adopted to obtain the embedding of each patient on different bipartite graphs. Finally, a multimodal fusion neural layer is designed to fuse the features from different modal data. The output of our method is the classification of short term survival or long term survival for each patient. Experimental results on one breast cancer dataset demonstrate that MGNN outperforms all baselines. Furthermore, we test the trained model on lung cancer dataset, and the experimental results verify the strong robust by comparing with state-of-the-art methods.},
address = {New York, NY, USA},
annote = {From Duplicate 1 (MGNN: A Multimodal Graph Neural Network for Predicting the Survival of Cancer Patients - Gao, Jianliang; Lyu, Tengfei; Xiong, Fan; Wang, Jianxin; Ke, Weimao; Li, Zhao)

$\backslash$citep{\{}Kim2019{\}} using DeepSurv in HNSCC
=

MDNNMD
[6] Dongdong Sun, Minghui Wang, and A o Li. 
A Multimodal Deep Neural Network for Human Breast Cancer Prognosis Prediction by Integrating Multi-Dimensional Data. TCBB, 16(3):841-850, 2018.

MDNNMD
=={\textgreater} 1. Sun, D., Wang, M. {\&} Li, A. A Multimodal Deep Neural Network for Human Breast Cancer Prognosis Prediction by Integrating Multi-Dimensional Data. IEEE/ACM Trans. Comput. Biol. Bioinforma. 16, 841–850 (2019). $\backslash$citep{\{}Sun2019{\}}},
author = {Gao, Jianliang and Lyu, Tengfei and Xiong, Fan and Wang, Jianxin and Ke, Weimao and Li, Zhao},
booktitle = {SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
doi = {10.1145/3397271.3401214},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Gao et al. - 2020 - MGNN A Multimodal Graph Neural Network for Predicting the Survival of Cancer Patients(2).pdf:pdf;:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Gao et al. - 2020 - MGNN A Multimodal Graph Neural Network for Predicting the Survival of Cancer Patients.docx:docx},
isbn = {9781450380164},
keywords = {cancer survival prediction,deep learning,graph neural networks,medical information retrieval,multimodal,survival},
mendeley-tags = {deep learning,survival},
month = {jul},
pages = {1697--1700},
publisher = {Association for Computing Machinery, Inc},
series = {SIGIR '20},
title = {{MGNN: A Multimodal Graph Neural Network for Predicting the Survival of Cancer Patients}},
url = {https://doi.org/10.1145/3397271.3401214 https://www.semanticscholar.org/paper/MGNN{\%}3A-A-Multimodal-Graph-Neural-Network-for-the-of-Gao-Lyu/acf3332e8ae664238f8cf18f903e004a390a271e/figure/0},
year = {2020}
}
@misc{HealthLevelSeven2019,
abstract = {the Fast Healthcare Interoperability Resources (FHIR) is a standard for health care data exchange, published by HL7{\textregistered}.},
author = {{Health Level Seven}},
booktitle = {the HL7 FHIR Foundation},
keywords = {FHIR},
mendeley-tags = {FHIR},
title = {{HL7{\textregistered} FHIR{\textregistered} v4.0.1}},
url = {http://hl7.org/fhir/},
urldate = {2021-03-09},
year = {2019}
}
@inproceedings{Bianchi2020,
abstract = {The biggest challenge to improve the diagnosis and therapies of Craniomaxillofacial conditions is to translate algorithms and software developments towards the creation of holistic patient models. A complete picture of the individual patient for treatment planning and personalized healthcare requires a compilation of clinician-friendly algorithms to provide minimally invasive diagnostic techniques with multimodal image integration and analysis. We describe here the implementation of the open-source Craniomaxillofacial module of the 3D Slicer software, as well as its clinical applications. This paper proposes data management approaches for multisource data extraction, registration, visualization, and quantification. These applications integrate medical images with clinical and biological data analytics, user studies, and other heterogeneous data.},
author = {Bianchi, Jonas and Paniagua, Beatriz and {De Oliveira Ruellas}, Antonio Carlos and Fillion-Robin, Jean Christophe and Prietro, Juan C and Gon{\c{c}}alves, Jo{\~{a}}o Roberto and Hoctor, James and Yatabe, Mar{\'{i}}lia and Styner, Martin and Li, Teng Fei and Gurgel, Marcela Lima and {Chaves Junior}, Cauby Maia and Massaro, Camila and Garib, Daniela Gamba and Vilanova, Lorena and Henriques, Jose Fernando Castanha and Castillo, Aron Aliaga Del and Janson, Guilherme and Iwasaki, Laura R and Nickel, Jeffrey C and Evangelista, Karine and Cevidanes, Lucia},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-030-60946-7_5},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Bianchi et al. - 2020 - 3D Slicer Craniomaxillofacial Modules Support Patient-Specific Decision-Making for Personalized Healthcare in De.pdf:pdf},
isbn = {9783030609450},
issn = {16113349},
keywords = {Craniomaxillofacial diseases,Data analytics,Data management,Dental research,Personalized medicine},
pages = {44--53},
pmid = {33415323},
publisher = {NIH Public Access},
title = {{3D Slicer Craniomaxillofacial Modules Support Patient-Specific Decision-Making for Personalized Healthcare in Dental Research}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/33415323 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC7786614},
volume = {12445 LNCS},
year = {2020}
}
@article{Chen2020a,
abstract = {Cancer diagnosis, prognosis, and therapeutic response predictions are based on morphological information from histology slides and molecular profiles from genomic data. However, most deep learning-based objective outcome prediction and grading paradigms are based on histology or genomics alone and do not make use of the complementary information in an intuitive manner. In this work, we propose Pathomic Fusion, an interpretable strategy for end-to-end multimodal fusion of histology image and genomic (mutations, CNV, RNASeq) features for survival outcome prediction. Our approach models pairwise feature interactions across modalities by taking the Kronecker product of unimodal feature representations, and controls the expressiveness of each representation via a gatingbased attention mechanism. Following supervised learning, we are able to interpret and saliently localize features across each modality, and understand how feature importance shifts when conditioning on multimodal input. We validate our approach using glioma and clear cell renal cell carcinoma datasets from the Cancer Genome Atlas (TCGA), which contains paired wholeslide image, genotype, and transcriptome data with ground truth survival and histologic grade labels. In a 15-fold cross-validation, our results demonstrate that the proposed multimodal fusion paradigm improves prognostic determinations from ground truth grading and molecular subtyping, as well as unimodal deep networks trained on histology and genomic data alone. The proposed method establishes insight and theory on how to train deep networks on multimodal biomedical data in an intuitive manner, which will be useful for other problems in medicine that seek to combine heterogeneous data streams for understanding diseases and predicting response and resistance to treatment. Code and trained models are made available at: https://github.com/mahmoodlab/PathomicFusion.},
annote = {https://github.com/mahmoodlab/PathomicFusion

Code Base Structure
The code base structure is explained below:
train{\_}cv.py: Cross-validation script for training unimodal and multimodal networks. This script will save evaluation metrics and predictions on the train + test split for each epoch on every split in checkpoints.
test{\_}cv.py: Script for testing unimodal and unimodal networks on only the test split.
train{\_}test.py: Contains the definitions for "train" and "test".
networks.py: Contains PyTorch model definitions for all unimodal and multimodal network.
fusion.py: Contains PyTorch model definitions for fusion.
data{\_}loaders.py: Contains the PyTorch DatasetLoader definition for loading multimodal data.
options.py: Contains all the options for the argparser.
make{\_}splits.py: Script for generating a pickle file that saves + aligns the path for multimodal data for cross-validation.
run{\_}cox{\_}baselines.py: Script for running Cox baselines.
utils.py: Contains definitions for collating, survival loss functions, data preprocessing, evaluation, figure plotting, etc...},
author = {Chen, Richard J and Lu, Ming Y and Wang, Jingwen and Williamson, Drew F K and Rodig, Scott J and Lindeman, Neal I and Mahmood, Faisal},
doi = {10.1109/TMI.2020.3021387},
file = {:Users/texchi/Downloads/10.1109@TMI.2020.3021387.pdf:pdf},
issn = {1558-254X (Electronic)},
journal = {IEEE transactions on medical imaging},
language = {eng},
month = {sep},
pmid = {32881682},
title = {{Pathomic Fusion: An Integrated Framework for Fusing Histopathology and Genomic Features for Cancer Diagnosis and Prognosis.}},
url = {https://pubmed.ncbi.nlm.nih.gov/32881682/},
volume = {PP},
year = {2020}
}
@article{Lai2020,
abstract = {Non-small cell lung cancer (NSCLC) is one of the most common lung cancers worldwide. Accurate prognostic stratification of NSCLC can become an important clinical reference when designing therapeutic strategies for cancer patients. With this clinical application in mind, we developed a deep neural network (DNN) combining heterogeneous data sources of gene expression and clinical data to accurately predict the overall survival of NSCLC patients. Based on microarray data from a cohort set (614 patients), seven well-known NSCLC biomarkers were used to group patients into biomarker- and biomarker+ subgroups. Then, by using a systems biology approach, prognosis relevance values (PRV) were then calculated to select eight additional novel prognostic gene biomarkers. Finally, the combined 15 biomarkers along with clinical data were then used to develop an integrative DNN via bimodal learning to predict the 5-year survival status of NSCLC patients with tremendously high accuracy (AUC: 0.8163, accuracy: 75.44{\%}). Using the capability of deep learning, we believe that our prediction can be a promising index that helps oncologists and physicians develop personalized therapy and build the foundation of precision medicine in the future.},
annote = {https://github.com/idssplab/overall{\_}survival{\_}nsclc},
author = {Lai, Yu-Heng and Chen, Wei-Ning and Hsu, Te-Cheng and Lin, Che and Tsao, Yu and Wu, Semon},
doi = {10.1038/s41598-020-61588-w},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Lai et al. - 2020 - Overall survival prediction of non-small cell lung cancer by integrating microarray and clinical data with deep lear.pdf:pdf},
issn = {2045-2322 (Electronic)},
journal = {Scientific reports},
keywords = {Area Under Curve,Biomarkers,Carcinoma,Computational Biology,Deep Learning,Humans,Kaplan-Meier Estimate,Lung Neoplasms,Microarray Analysis,Neoplasm Grading,Neoplasm Metastasis,Neoplasm Staging,Non-Small-Cell Lung,Reproducibility of Results,Support Vector Machine,Tumor,Workflow,diagnosis,etiology,methods,mortality},
language = {eng},
month = {mar},
number = {1},
pages = {4679},
pmid = {32170141},
title = {{Overall survival prediction of non-small cell lung cancer by integrating microarray and clinical data with deep learning.}},
url = {https://www.nature.com/articles/s41598-020-61588-w},
volume = {10},
year = {2020}
}
@article{Zhao2020a,
abstract = {PURPOSE: This study endeavors to build a deep learning (DL)-based model for predicting disease progression in head and neck squamous cell carcinoma (HNSCC) patients by integrating multi-omics data. METHODS: RNA sequencing, miRNA sequencing, and methylation data from The Cancer Genome Atlas (TCGA) were used as input for autoencoder, a DL approach. An autoencoder-based prognosis model for PFS was built by SVM algorithm and tested in three confirmation sets. Predictive performance of the model was compared to two alternative approaches. Differential expression analysis for mRNAs, microRNAs (miRNA) and methylation was conducted. Moreover, functional annotation of differentially expressed genes (DEGs) was achieved through function enrichment analysis. RESULT: The DL-based prognosis model identified two subgroups of patients with significantly different PFS, and showcased a good model fitness (C-index = 0.73). The two identified PFS subtypes were successfully validated in three confirmation sets. The DL-based model was more accurate and efficient than principal component analysis (PCA) or individual Cox-PH-based models. There were 348 DEGs, 23 differentially expressed miRNAs and 55 differentially methylated genes between the two PFS subtypes. These genes were significantly involved in several immune-related biological processes and primary immunodeficiency, cell adhesion molecules (CAMs), B cell receptor signaling and leukocyte transendothelial migration pathways. CONCLUSION: The DL-based model introduced in this study is reliable and robust in predicting disease progression in HNSCC patients. A number of pathways and genes targets are unraveled to be implicated in cancer progression. Utility of this model would facilitate development of more individualized therapy for HNSCC patients and improve prognosis.},
author = {Zhao, Zhen and Li, Yingli and Wu, Yuanqing and Chen, Rongrong},
doi = {10.3233/CBM-190380},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Zhao et al. - 2020 - Deep learning-based model for predicting progression in patients with head and neck squamous cell carcinoma.pdf:pdf},
issn = {1875-8592 (Electronic)},
journal = {Cancer biomarkers : section A of Disease markers},
keywords = {Biomarkers,Cell Adhesion Molecules,Computational Biology,Cox,Deep Learning,Disease Progression,Female,Gene Expression Regulation,Humans,Male,Messenger,Middle Aged,Neoplastic,Prognosis,Progression-Free Survival,RNA,RNA-Seq,SVM,Signal Transduction,Squamous Cell Carcinoma of Head and Neck,Transcriptome,Tumor,autoencoder,epidemiology,genetics,pathology},
language = {eng},
mendeley-tags = {Cox,SVM,autoencoder},
number = {1},
pages = {19--28},
pmid = {31658045},
title = {{Deep learning-based model for predicting progression in patients with head and neck squamous cell carcinoma.}},
url = {https://content.iospress.com/articles/cancer-biomarkers/cbm190380},
volume = {27},
year = {2020}
}
@article{Hao2019a,
abstract = {BACKGROUND: Understanding the complex biological mechanisms of cancer patient survival using genomic and clinical data is vital, not only to develop new treatments for patients, but also to improve survival prediction. However, highly nonlinear and high-dimension, low-sample size (HDLSS) data cause computational challenges to applying conventional survival analysis. RESULTS: We propose a novel biologically interpretable pathway-based sparse deep neural network, named Cox-PASNet, which integrates high-dimensional gene expression data and clinical data on a simple neural network architecture for survival analysis. Cox-PASNet is biologically interpretable where nodes in the neural network correspond to biological genes and pathways, while capturing the nonlinear and hierarchical effects of biological pathways associated with cancer patient survival. We also propose a heuristic optimization solution to train Cox-PASNet with HDLSS data. Cox-PASNet was intensively evaluated by comparing the predictive performance of current state-of-the-art methods on glioblastoma multiforme (GBM) and ovarian serous cystadenocarcinoma (OV) cancer. In the experiments, Cox-PASNet showed out-performance, compared to the benchmarking methods. Moreover, the neural network architecture of Cox-PASNet was biologically interpreted, and several significant prognostic factors of genes and biological pathways were identified. CONCLUSIONS: Cox-PASNet models biological mechanisms in the neural network by incorporating biological pathway databases and sparse coding. The neural network of Cox-PASNet can identify nonlinear and hierarchical associations of genomic and clinical data to cancer patient survival. The open-source code of Cox-PASNet in PyTorch implemented for training, evaluation, and model interpretation is available at: https://github.com/DataX-JieHao/Cox-PASNet.},
annote = {From Duplicate 2 (Interpretable deep neural network for cancer survival analysis by integrating genomic and clinical data - Hao, Jie; Kim, Youngsoon; Mallavarapu, Tejaswini; Oh, Jung Hun; Kang, Mingon)

https://github.com/DataX-JieHao/Cox-PASNet

highly nonlinear and high-dimension, low-sample size (HDLSS) data cause computational challenges to applying conventional survival analysis.

Gene layer: global protein-coding genes, RNA-Seq dataset from TCGA GBM cohort

Selected articles from the IEEE BIBM International Conference on Bioinformatics {\&} Biomedicine (BIBM) 2018: medical genomics},
author = {Hao, Jie and Kim, Youngsoon and Mallavarapu, Tejaswini and Oh, Jung Hun and Kang, Mingon},
doi = {10.1186/s12920-019-0624-2},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Hao et al. - 2019 - Interpretable deep neural network for cancer survival analysis by integrating genomic and clinical data.pdf:pdf},
issn = {1755-8794 (Electronic)},
journal = {BMC Medical Genomics},
keywords = {Computational Biology,Cox proportional hazards analyses,Cox-PASNet,Deep Learning,Deep neural network,Glioblastoma multiforme,Humans,Neoplasms,Ovarian cancer,Proportional Hazards Models,PyTorch,Survival analysis,deep learning,genetics,methods,survival},
language = {eng},
mendeley-tags = {Cox proportional hazards analyses,Cox-PASNet,PyTorch,deep learning,survival},
month = {dec},
number = {S10},
pages = {189},
pmid = {31865908},
publisher = {BioMed Central},
title = {{Interpretable deep neural network for cancer survival analysis by integrating genomic and clinical data}},
url = {https://bmcmedgenomics.biomedcentral.com/articles/10.1186/s12920-019-0624-2},
volume = {12},
year = {2019}
}
@misc{Suresh2017,
abstract = {Real-time prediction of clinical interventions remains a challenge within intensive care units (ICUs). This task is complicated by data sources that are noisy, sparse, heterogeneous and outcomes that are imbalanced. In this paper, we integrate data from all available ICU sources (vitals, labs, notes, demographics) and focus on learning rich representations of this data to predict onset and weaning of multiple invasive interventions. In particular, we compare both long short-term memory networks (LSTM) and convolutional neural networks (CNN) for prediction of five intervention tasks: invasive ventilation, non-invasive ventilation, vasopressors, colloid boluses, and crystalloid boluses. Our predictions are done in a forward-facing manner to enable "real-time" performance, and predictions are made with a six hour gap time to support clinically actionable planning. We achieve state-of-the-art results on our predictive tasks using deep architectures. We explore the use of feature occlusion to interpret LSTM models, and compare this to the interpretability gained from examining inputs that maximally activate CNN outputs. We show that our models are able to significantly outperform baselines in intervention prediction, and provide insight into model learning, which is crucial for the adoption of such models in practice.},
archivePrefix = {arXiv},
arxivId = {1705.08498},
author = {Suresh, Harini and Hunt, Nathan and Johnson, Alistair and Celi, Leo Anthony and Szolovits, Peter and Ghassemi, Marzyeh},
booktitle = {arXiv},
eprint = {1705.08498},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Suresh et al. - 2017 - Clinical Intervention Prediction and Understanding using Deep Networks.pdf:pdf},
issn = {23318422},
keywords = {XAI},
mendeley-tags = {XAI},
month = {may},
title = {{Clinical intervention prediction and understanding using deep networks}},
url = {http://arxiv.org/abs/1705.08498},
year = {2017}
}
@inproceedings{Giunchiglia2018a,
abstract = {Current medical practice is driven by clinical guidelines which are designed for the “average” patient. Deep learning is enabling medicine to become personalized to the patient at hand. In this paper we present a new recurrent neural network model for personalized survival analysis called rnn-surv. Our model is able to exploit censored data to compute both the risk score and the survival function of each patient. At each time step, the network takes as input the features characterizing the patient and the identifier of the time step, creates an embedding, and outputs the value of the survival function in that time step. Finally, the values of the survival function are linearly combined to compute the unique risk score. Thanks to the model structure and the training designed to exploit two loss functions, our model gets better concordance index (C-index) than the state of the art approaches.},
address = {Cham},
annote = {https://github.com/data-modeler/rnn-surv},
author = {Giunchiglia, Eleonora and Nemchenko, Anton and van der Schaar, Mihaela},
editor = {Kůrkov{\'{a}}, V{\v{e}}ra and Manolopoulos, Yannis and Hammer, Barbara and Iliadis, Lazaros and Maglogiannis, Ilias},
file = {:Users/texchi/Downloads/RNN{\_}SURV.pdf:pdf},
isbn = {978-3-030-01424-7},
keywords = {RNN-SURV,censoring},
mendeley-tags = {RNN-SURV,censoring},
pages = {23--32},
publisher = {Springer International Publishing},
title = {{RNN-SURV: A Deep Recurrent Model for Survival Analysis BT - Artificial Neural Networks and Machine Learning – ICANN 2018}},
url = {https://link.springer.com/chapter/10.1007/978-3-030-01424-7{\_}3},
year = {2018}
}
@misc{Moncada-Torres2020,
author = {Moncada-Torres, Arturo},
title = {{DeepSurvK}},
url = {https://deepsurvk.readthedocs.io/en/latest/},
year = {2020}
}
@misc{Kelly2019,
abstract = {Background: Artificial intelligence (AI) research in healthcare is accelerating rapidly, with potential applications being demonstrated across various domains of medicine. However, there are currently limited examples of such techniques being successfully deployed into clinical practice. This article explores the main challenges and limitations of AI in healthcare, and considers the steps required to translate these potentially transformative technologies from research to clinical practice. Main body: Key challenges for the translation of AI systems in healthcare include those intrinsic to the science of machine learning, logistical difficulties in implementation, and consideration of the barriers to adoption as well as of the necessary sociocultural or pathway changes. Robust peer-reviewed clinical evaluation as part of randomised controlled trials should be viewed as the gold standard for evidence generation, but conducting these in practice may not always be appropriate or feasible. Performance metrics should aim to capture real clinical applicability and be understandable to intended users. Regulation that balances the pace of innovation with the potential for harm, alongside thoughtful post-market surveillance, is required to ensure that patients are not exposed to dangerous interventions nor deprived of access to beneficial innovations. Mechanisms to enable direct comparisons of AI systems must be developed, including the use of independent, local and representative test sets. Developers of AI algorithms must be vigilant to potential dangers, including dataset shift, accidental fitting of confounders, unintended discriminatory bias, the challenges of generalisation to new populations, and the unintended negative consequences of new algorithms on health outcomes. Conclusion: The safe and timely translation of AI research into clinically validated and appropriately regulated systems that can benefit everyone is challenging. Robust clinical evaluation, using metrics that are intuitive to clinicians and ideally go beyond measures of technical accuracy to include quality of care and patient outcomes, is essential. Further work is required (1) to identify themes of algorithmic bias and unfairness while developing mitigations to address these, (2) to reduce brittleness and improve generalisability, and (3) to develop methods for improved interpretability of machine learning predictions. If these goals can be achieved, the benefits for patients are likely to be transformational.},
annote = {to develop methods for improved interpretability of machine learning predictions

Algorithmic interpretability is at an early stage but rapidly advancing
While AI approaches in medicine have yielded some impressive practical successes to date, their effectiveness is limited by their inability to ‘explain' their decision-making in an understandable way 

At present, a trade-off exists between performance and explainability. The best performing models (e.g. deep learning) are often the least explainable, whereas models with poorer performance (e.g. linear regression, decision trees) are the most explainable.

Explainable AI approaches are likely to facilitate faster adoption of AI systems into the clinical healthcare setting, and will help foster vital transparency and trust with their users.

所以第一線試用 IBM Watson for Oncology 已經失敗（不能只看結果）

survival analysis or biomarker discovery 則沒有那麼 critical need for Explainable AI.},
author = {Kelly, Christopher J. and Karthikesalingam, Alan and Suleyman, Mustafa and Corrado, Greg and King, Dominic},
booktitle = {BMC Medicine},
doi = {10.1186/s12916-019-1426-2},
issn = {17417015},
keywords = {Algorithms,Artificial intelligence,Evaluation,Machine learning,Regulation,Translation,deep learning,interpretability},
mendeley-tags = {deep learning,interpretability},
number = {1},
pages = {1--9},
pmid = {31665002},
title = {{Key challenges for delivering clinical impact with artificial intelligence}},
url = {https://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-019-1426-2},
volume = {17},
year = {2019}
}
@article{Chai2020,
abstract = {New therapeutic targets for oral squamous cell carcinoma (OSCC) are urgently needed. We conducted genome-wide CRISPR-Cas9 screens in 21 OSCC cell lines, primarily derived from Asians, to identify genetic vulnerabilities that can be explored as therapeutic targets. We identify known and novel fitness genes and demonstrate that many previously identified OSCC-related cancer genes are non-essential and could have limited therapeutic value, while other fitness genes warrant further investigation for their potential as therapeutic targets. We validate a distinctive dependency on YAP1 and WWTR1 of the Hippo pathway, where the lost-of-fitness effect of one paralog can be compensated only in a subset of lines. We also discover that OSCCs with WWTR1 dependency signature are significantly associated with biomarkers of favourable response towards immunotherapy. In summary, we have delineated the genetic vulnerabilities of OSCC, enabling the prioritization of therapeutic targets for further exploration, including the targeting of YAP1 and WWTR1.},
author = {Chai, Annie Wai Yeeng and Yee, Pei San and Price, Stacey and Yee, Shi Mun and Lee, Hui Mei and Tiong, Vivian K.H. and Gon{\c{c}}alves, Emanuel and Behan, Fiona M. and Bateson, Jessica and Gilbert, James and Tan, Aik Choon and McDermott, Ultan and Garnett, Mathew J. and Cheong, Sok Ching},
doi = {10.7554/ELIFE.57761},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Chai et al. - 2020 - Genome-wide CRISPR screens of oral squamous cell carcinoma reveal fitness genes in the hippo pathway.pdf:pdf},
issn = {2050084X},
journal = {eLife},
keywords = {CRISPR screen,Fitness genes,HNSCC,Hippo pathway,Oral squamous cell carcinoma,Therapeutic targets,betel nut,hipo},
mendeley-tags = {HNSCC,betel nut,hipo},
month = {sep},
pages = {1--81},
pmid = {32990596},
publisher = {eLife Sciences Publications Ltd},
title = {{Genome-wide CRISPR screens of oral squamous cell carcinoma reveal fitness genes in the hippo pathway}},
volume = {9},
year = {2020}
}
@inproceedings{Giunchiglia2018,
abstract = {Current medical practice is driven by clinical guidelines which are designed for the “average” patient. Deep learning is enabling medicine to become personalized to the patient at hand. In this paper we present a new recurrent neural network model for personalized survival analysis called rnn-surv. Our model is able to exploit censored data to compute both the risk score and the survival function of each patient. At each time step, the network takes as input the features characterizing the patient and the identifier of the time step, creates an embedding, and outputs the value of the survival function in that time step. Finally, the values of the survival function are linearly combined to compute the unique risk score. Thanks to the model structure and the training designed to exploit two loss functions, our model gets better concordance index (C-index) than the state of the art approaches.},
author = {Giunchiglia, Eleonora and Nemchenko, Anton and van der Schaar, Mihaela},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-030-01424-7_3},
file = {:Users/texchi/Downloads/RNN{\_}SURV.pdf:pdf},
isbn = {9783030014230},
issn = {16113349},
keywords = {RNN-SURV},
mendeley-tags = {RNN-SURV},
pages = {23--32},
title = {{RNN-SURV: A Deep Recurrent Model for Survival Analysis BT - Artificial Neural Networks and Machine Learning – ICANN 2018}},
year = {2018}
}
@inproceedings{Lee2018a,
abstract = {Survival analysis (time-to-event analysis) is widely used in economics and finance, engineering, medicine and many other areas. A fundamental problem is to understand the relationship between the covariates and the (distribution of) survival times (times-to-event). Much of the previous work has approached the problem by viewing the survival time as the first hitting time of a stochastic process, assuming a specific form for the underlying stochastic process, using available data to learn the relationship between the covariates and the parameters of the model, and then deducing the relationship between covariates and the distribution of first hitting times (the risk). However, previous models rely on strong parametric assumptions that are often violated. This paper proposes a very different approach to survival analysis, DeepHit, that uses a deep neural network to learn the distribution of survival times directly. DeepHit makes no assumptions about the underlying stochastic process and allows for the possibility that the relationship between covariates and risk(s) changes over time. Most importantly, DeepHit smoothly handles competing risks; i.e. settings in which there is more than one possible event of interest. Comparisons with previous models on the basis of real and synthetic datasets demonstrate that DeepHit achieves large and statistically significant performance improvements over previous state-of-the-art methods.},
annote = {https://humboldt-wi.github.io/blog/research/information{\_}systems{\_}1920/group2{\_}survivalanalysis/{\#}rsf

={\textgreater} a improvement by 
https://www.groundai.com/project/feature-selection-for-survival-analysis-with-competing-risks-using-deep-learning/1
https://arxiv.org/abs/1811.09317v4
DeeoHit+


software
https://bitbucket.org/mvdschaar/mlforhealthlabpub/src/f75f292e53e9485d742e865e55751f66f19dcf86/alg/deephit/
https://github.com/texchi2/DeepHit

Supplementary: http://medianetlab.ee.ucla.edu/papers/AAAI{\_}2018{\_}DeepHit{\_}Appendix},
author = {Lee, Changhee and Zame, William R. and Yoon, Jinsung and {Van Der Schaar}, Mihaela},
booktitle = {32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
file = {:Users/texchi/Downloads/AAAI{\_}2018{\_}DeepHit.pdf:pdf},
isbn = {9781577358008},
keywords = {DeepHit,competing risks,deep learning,first-hitting-time analysis,neural networks,survi,survival analysis,tensorflow},
mendeley-tags = {DeepHit,deep learning,survi,tensorflow},
pages = {2314--2321},
title = {{DeepHit: A deep learning approach to survival analysis with competing risks}},
url = {https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16160 https://github.com/chl8856/DeepHit},
year = {2018}
}
@misc{Iqbal2020,
abstract = {In this paper we propose the idea that Artificial intelligence (AI) is ushering in a new era of "Earlier Medicine," which is a predictive approach for disease prevention based on AI modeling and big data. The flourishing health care technological landscape is showing great potential-from diagnosis and prescription automation to the early detection of disease through efficient and cost-effective patient data screening tools that benefit from the predictive capabilities of AI. Monitoring the trajectories of both in- A nd outpatients has proven to be a task AI can perform to a reliable degree. Predictions can be a significant advantage to health care if they are accurate, prompt, and can be personalized and acted upon efficiently. This is where AI plays a crucial role in "Earlier Medicine" implementation.},
author = {Iqbal, Usman and Celi, Leo Anthony and Li, Yu Chuan Jack},
booktitle = {Journal of Medical Internet Research},
doi = {10.2196/17211},
issn = {14388871},
keywords = {Advanced care systems,Artificial intelligence,Digital health,Health care technology,Health information technology,Medical innovations,deep learning,eHealth},
mendeley-tags = {deep learning},
number = {8},
pages = {e17211},
pmid = {32780024},
title = {{How can artificial intelligence make medicine more preemptive?}},
url = {https://www.jmir.org/2020/8/e17211},
volume = {22},
year = {2020}
}
@article{Ren2019,
abstract = {Survival analysis is a hotspot in statistical research for modeling time-to-event information with data censorship handling, which has been widely used in many applications such as clinical research, information system and other fields with survivorship bias. Many works have been proposed for survival analysis ranging from traditional statistic methods to machine learning models. However, the existing methodologies either utilize counting-based statistics on the segmented data, or have a pre-assumption on the event probability distribution w.r.t. time. Moreover, few works consider sequential patterns within the feature space. In this paper, we propose a Deep Recurrent Survival Analysis model which combines deep learning for conditional probability prediction at finegrained level of the data, and survival analysis for tackling the censorship. By capturing the time dependency through modeling the conditional probability of the event for each sample, our method predicts the likelihood of the true event occurrence and estimates the survival rate over time, i.e., the probability of the non-occurrence of the event, for the censored data. Meanwhile, without assuming any specific form of the event probability distribution, our model shows great advantages over the previous works on fitting various sophisticated data distributions. In the experiments on the three realworld tasks from different fields, our model significantly outperforms the state-of-the-art solutions under various metrics.},
archivePrefix = {arXiv},
arxivId = {1809.02403},
author = {Ren, Kan and Qin, Jiarui and Zheng, Lei and Yang, Zhengyu and Zhang, Weinan and Qiu, Lin and Yu, Yong},
doi = {10.1609/aaai.v33i01.33014798},
eprint = {1809.02403},
file = {:Users/texchi/Downloads/4407-Article Text-7446-1-10-20190706.pdf:pdf},
isbn = {9781577358091},
issn = {2374-3468},
journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
keywords = {L2L,NAS,RNN,architecture search,censoring,deep learning,evolution,evolutionary algorithms,genetic algorithms,image classification,learning to learn,learning-to-learn,meta learning,meta-learning,neural networks,neuro-evolution,neuroevolution,reinforcement,reinforcement learning,rl},
mendeley-tags = {RNN,censoring,deep learning},
month = {jul},
number = {01 SE - AAAI Technical Track: Machine Learning},
pages = {4798--4805},
title = {{Deep Recurrent Survival Analysis}},
url = {https://ojs.aaai.org/index.php/AAAI/article/view/4407 https://aaai.org/ojs/index.php/AAAI/article/view/4407},
volume = {33},
year = {2019}
}
@article{Ren2019a,
abstract = {{\textless}p{\textgreater}Survival analysis is a hotspot in statistical research for modeling time-to-event information with data censorship handling, which has been widely used in many applications such as clinical research, information system and other fields with survivorship bias. Many works have been proposed for survival analysis ranging from traditional statistic methods to machine learning models. However, the existing methodologies either utilize counting-based statistics on the segmented data, or have a pre-assumption on the event probability distribution w.r.t. time. Moreover, few works consider sequential patterns within the feature space. In this paper, we propose a Deep Recurrent Survival Analysis model which combines deep learning for conditional probability prediction at finegrained level of the data, and survival analysis for tackling the censorship. By capturing the time dependency through modeling the conditional probability of the event for each sample, our method predicts the likelihood of the true event occurrence and estimates the survival rate over time, i.e., the probability of the {\textless}em{\textgreater}non{\textless}/em{\textgreater}-occurrence of the event, for the censored data. Meanwhile, without assuming any specific form of the event probability distribution, our model shows great advantages over the previous works on fitting various sophisticated data distributions. In the experiments on the three realworld tasks from different fields, our model significantly outperforms the state-of-the-art solutions under various metrics.{\textless}/p{\textgreater}},
author = {Ren, Kan and Qin, Jiarui and Zheng, Lei and Yang, Zhengyu and Zhang, Weinan and Qiu, Lin and Yu, Yong},
doi = {10.1609/aaai.v33i01.33014798},
journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
month = {jul},
number = {01 SE  - AAAI Technical Track: Machine Learning},
pages = {4798--4805},
title = {{Deep Recurrent Survival Analysis}},
url = {https://ojs.aaai.org/index.php/AAAI/article/view/4407},
volume = {33},
year = {2019}
}
@article{Jeong2020,
abstract = {Background: Artificial Intelligence (AI) frameworks have emerged as a novel approach in medicine. However, information regarding its applicability and effectiveness in a clinical prognostic factor setting remains unclear. Methods: The AI framework was derived from a pooled dataset of intrahepatic cholangiocarcinoma (ICC) patients from three clinical centers (n = 1,421) by applying the TensorFlow deep learning algorithm to Cox-indicated pathologic (four), serologic (six), and etiologic (two) factors; this algorithm was validated using a dataset of ICC patients from an independent clinical center (n = 234). The model was compared to the commonly used staging system (American Joint Committee on Cancer; AJCC) and methodology (Cox regression) by evaluating the brier score (BS), integrated discrimination improvement (IDI), net reclassification improvement (NRI), and area under curve (AUC) values. Results: The framework (BS, 0.17; AUC, 0.78) was found to be more accurate than the AJCC stage (BS, 0.48; AUC, 0.60; IDI, 0.29; NRI, 11.85; P {\textless} 0.001) and the Cox model (BS, 0.49; AUC, 0.70; IDI, 0.46; NRI, 46.11; P {\textless} 0.001). Furthermore, hazard ratios greater than three were identified in both overall survival (HR; 3.190; 95{\%} confidence interval [CI], 2.150–4.733; P {\textless} 0.001) and disease-free survival (HR, 3.559; 95{\%} CI, 2.500–5.067; P {\textless} 0.001) between latent risk and stable groups in validation. In addition, the latent risk subgroup was found to be significantly benefited from adjuvant treatment (HR, 0.459; 95{\%} CI, 0.360–0.586; P {\textless} 0.001). Conclusions: The AI framework seems promising in the prognostic estimation and stratification of susceptible individuals for adjuvant treatment in patients with ICC after resection. Future prospective validations are needed for the framework to be applied in clinical practice.},
author = {Jeong, Seogsong and Ge, Yang and Chen, Jing and Gao, Qiang and Luo, Guijuan and Zheng, Bo and Sha, Meng and Shen, Feng and Cheng, Qingbao and Sui, Chengjun and Liu, Jingfeng and Wang, Hongyang and Xia, Qiang and Chen, Lei},
doi = {10.3389/fonc.2020.00143},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Jeong et al. - 2020 - Latent Risk Intrahepatic Cholangiocarcinoma Susceptible to Adjuvant Treatment After Resection A Clinical Deep Lear.pdf:pdf},
issn = {2234943X},
journal = {Frontiers in Oncology},
keywords = {Cox,TensorFlow,artificial intelligence,biliary malignancy,deep learning,prediction model,primary liver cancer,prognostic factor,survival analysis},
mendeley-tags = {Cox,TensorFlow,deep learning,survival analysis},
month = {feb},
publisher = {Frontiers Media S.A.},
title = {{Latent Risk Intrahepatic Cholangiocarcinoma Susceptible to Adjuvant Treatment After Resection: A Clinical Deep Learning Approach}},
volume = {10},
year = {2020}
}
@article{Ramirez2021,
abstract = {The survival rate of cancer has increased significantly during the past two decades for breast, prostate, testicular, and colon cancer, while the brain and pancreatic cancers have a much lower median survival rate that has not improved much over the last forty years. This has imposed the challenge of finding gene markers for early cancer detection and treatment strategies. Different methods including regression-based Cox-PH, artificial neural networks, and recently deep learning algorithms have been proposed to predict the survival rate for cancers. We established in this work a novel graph convolution neural network (GCNN) approach called Surv{\_}GCNN to predict the survival rate for 13 different cancer types using the TCGA dataset. For each cancer type, 6 Surv{\_}GCNN models with graphs generated by correlation analysis, GeneMania database, and correlation + GeneMania were trained with and without clinical data to predict the risk score (RS). The performance of the 6 Surv{\_}GCNN models was compared with two other existing models, Cox-PH and Cox-nnet. The results showed that Cox-PH has the worst performance among 8 tested models across the 13 cancer types while Surv{\_}GCNN models with clinical data reported the best overall performance, outperforming other competing models in 7 out of 13 cancer types including BLCA, BRCA, COAD, LUSC, SARC, STAD, and UCEC. A novel network-based interpretation of Surv{\_}GCNN was also proposed to identify potential gene markers for breast cancer. The signatures learned by the nodes in the hidden layer of Surv{\_}GCNN were identified and were linked to potential gene markers by network modularization. The identified gene markers for breast cancer have been compared to a total of 213 gene markers from three widely cited lists for breast cancer survival analysis. About 57{\%} of gene markers obtained by Surv{\_}GCNN with correlation + GeneMania graph either overlap or directly interact with the 213 genes, confirming the effectiveness of the identified markers by Surv{\_}GCNN.},
annote = {Highlights
•
Predicting cancer survival outcomes using Graph Convolutional Neural Networks with TCGA dataset.
•
Combining clinical data and the GCNN improves cancer prognostic prediction.
•
Interpreting the GCNN model and identifying significant genes with network modules identified by HotNet2.},
author = {Ramirez, Ricardo and Chiu, Yu-Chiao and Zhang, SongYao and Ramirez, Joshua and Chen, Yidong and Huang, Yufei and Jin, Yu-Fang},
doi = {10.1016/J.YMETH.2021.01.004},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Ramirez et al. - 2021 - Prediction and interpretation of cancer survival using graph convolution neural networks.pdf:pdf},
issn = {1046-2023},
journal = {Methods},
keywords = {GCNN},
mendeley-tags = {GCNN},
month = {jan},
publisher = {Academic Press},
title = {{Prediction and interpretation of cancer survival using graph convolution neural networks}},
url = {https://www.sciencedirect.com/science/article/pii/S1046202321000165?via{\%}3Dihub},
year = {2021}
}
@article{Garmire2020,
abstract = {Purpose: Pathological images are easily accessible data with the potential as prognostic biomarkers. Moreover, integration of heterogeneous data types from multi-modality, such as pathological image and gene expression data, is invaluable to help predicting cancer patient survival. However, the analytical challenges are significant. Experimental Design: Here we take the hepatocellular carcinoma (HCC) pathological image features extracted by CellProfiler, and apply them as the input for Cox-nnet, a neural network-based prognosis. We compare this model with conventional Cox-PH models, using C-index and log ranked p-values on HCC testing samples. Further, to integrate pathological image and gene expression data of the same patients, we innovatively construct a two-stage Cox-nnet model, and compare it with another complex neural network model PAGE-Net. Results: pathological image based prognosis prediction using Cox-nnet (median C-index 0.74 and log-rank p-value 4e-6) is significantly more accurate than Cox-PH model (median C-index 0.72 and log-rank p-value of 3e-4). Moreover, the two-stage Cox-nnet complex model combining histopathology image and transcriptomics RNA-Seq data achieves better prognosis prediction, with a median C-index of 0.75 and log-rank p-value of 6e-7 in the testing datasets. The results are much more accurate than PAGE-Net, a CNN based complex model (median C-index of 0.67 and log-rank p-value of 0.02). Imaging features present additional predictive information to gene expression features, as the combined model is much more accurate than the model with gene expression alone (median C-index 0.70). Pathological image features are modestly correlated with gene expression. Genes having correlations to top imaging features have known associations with HCC patient survival and morphogenesis of liver tissue. Conclusion: This work provides two-stage Cox-nnet, a new class of biologically relevant and relatively interpretable models, to integrate multi-modal and multiple types of data for survival prediction. {\#}{\#}{\#} Competing Interest Statement The authors have declared no competing interest. {\#}{\#}{\#} Clinical Trial This study is a secondary data analysis on public pathology and genomics dataset in TCGA. {\#}{\#}{\#} Funding Statement The work is support by grants K01ES025434 awarded by NIEHS through funds provided by the trans-NIH Big Data to Knowledge (BD2K) initiative (www.bd2k.nih.gov), R01 LM012373 and LM012907 awarded by NLM, R01 HD084633 awarded by NICHD to L.X. Garmire. {\#}{\#}{\#} Author Declarations All relevant ethical guidelines have been followed; any necessary IRB and/or ethics committee approvals have been obtained and details of the IRB/oversight body are included in the manuscript. Yes All necessary patient/participant consent has been obtained and the appropriate institutional forms have been archived. Yes I understand that all clinical trials and any other prospective interventional studies must be registered with an ICMJE-approved registry, such as ClinicalTrials.gov. I confirm that any such study reported in the manuscript has been registered and the trial registration ID is provided (note: if posting a prospective study registered retrospectively, please provide a statement in the trial ID field explaining why the study was not registered in advance). Yes I have followed all appropriate research reporting guidelines and uploaded the relevant EQUATOR Network research reporting checklist(s) and other pertinent material as supplementary files, if applicable. Yes All data used in this study is publicly available. {\textless}gs://gdc-tcga-phs000178-open/{\textgreater}},
author = {Garmire, Lana and Zhan, Zhucheng and Jing, Zheng and He, Bing and Hossenei, Noshad and Westerhoff, Maria and Choi, Eun-Young},
doi = {10.1101/2020.01.25.20016832},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Garmire et al. - 2020 - Two-stage biologically interpretable neural-network models for liver cancer prognosis prediction using histopath.pdf:pdf},
journal = {medRxiv},
keywords = {cox-nnet},
mendeley-tags = {cox-nnet},
month = {aug},
pages = {2020.01.25.20016832},
publisher = {Cold Spring Harbor Laboratory Press},
title = {{Two-stage biologically interpretable neural-network models for liver cancer prognosis prediction using histopathology and transcriptomic data}},
url = {https://www.medrxiv.org/content/10.1101/2020.01.25.20016832v2},
year = {2020}
}
@article{Meglioli2020,
abstract = {This systematic review aimed to evaluate the use of three-dimensional (3D) printed bone models for training, simulating and/or planning interventions in oral and cranio-maxillofacial surgery. A systematic search was conducted using PubMed{\textregistered} and SCOPUS{\textregistered} databases, up to March 10, 2019, by following the Preferred Reporting Items for Systematic reviews and Meta-Analysis (PRISMA) protocol. Study selection, quality assessment (modified Critical Appraisal Skills Program tool) and data extraction were performed by two independent reviewers. All original full papers written in English/French/Italian and dealing with the fabrication of 3D printed models of head bone structures, designed from 3D radiological data were included. Multiple parameters and data were investigated, such as author's purpose, data acquisition systems, printing technologies and materials, accuracy, haptic feedback, variations in treatment time, differences in clinical outcomes, costs, production time and cost-effectiveness. Among the 1157 retrieved abstracts, only 69 met the inclusion criteria. 3D printed bone models were mainly used as training or simulation models for tumor removal, or bone reconstruction. Material jetting printers showed best performance but the highest cost. Stereolithographic, laser sintering and binder jetting printers allowed to create accurate models with adequate haptic feedback. The cheap fused deposition modeling printers exhibited satisfactory results for creating training models. Patient-specific 3D printed models are known to be useful surgical and educational tools. Faced with the large diversity of software, printing technologies and materials, the clinical team should invest in a 3D printer specifically adapted to the final application.},
author = {Meglioli, Matteo and Naveau, Adrien and Macaluso, Guido Maria and Catros, Sylvain},
doi = {10.1186/s41205-020-00082-5},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Meglioli et al. - 2020 - 3D printed bone models in oral and cranio-maxillofacial surgery a systematic review.pdf:pdf},
issn = {2365-6271},
journal = {3D Printing in Medicine},
keywords = {Biomaterials,Biomedical Engineering and Bioengineering,Imaging / Radiology,Surgery},
month = {dec},
number = {1},
pages = {30},
publisher = {BioMed Central},
title = {{3D printed bone models in oral and cranio-maxillofacial surgery: a systematic review}},
url = {https://threedmedprint.biomedcentral.com/articles/10.1186/s41205-020-00082-5},
volume = {6},
year = {2020}
}
@article{Ren2019,
abstract = {Survival analysis is a hotspot in statistical research for modeling time-to-event information with data censorship handling, which has been widely used in many applications such as clinical research, information system and other fields with survivorship bias. Many works have been proposed for survival analysis ranging from traditional statistic methods to machine learning models. However, the existing methodologies either utilize counting-based statistics on the segmented data, or have a pre-assumption on the event probability distribution w.r.t. time. Moreover, few works consider sequential patterns within the feature space. In this paper, we propose a Deep Recurrent Survival Analysis model which combines deep learning for conditional probability prediction at finegrained level of the data, and survival analysis for tackling the censorship. By capturing the time dependency through modeling the conditional probability of the event for each sample, our method predicts the likelihood of the true event occurrence and estimates the survival rate over time, i.e., the probability of the non-occurrence of the event, for the censored data. Meanwhile, without assuming any specific form of the event probability distribution, our model shows great advantages over the previous works on fitting various sophisticated data distributions. In the experiments on the three realworld tasks from different fields, our model significantly outperforms the state-of-the-art solutions under various metrics.},
archivePrefix = {arXiv},
arxivId = {1809.02403},
author = {Ren, Kan and Qin, Jiarui and Zheng, Lei and Yang, Zhengyu and Zhang, Weinan and Qiu, Lin and Yu, Yong},
doi = {10.1609/aaai.v33i01.33014798},
eprint = {1809.02403},
file = {:Users/texchi/Downloads/4407-Article Text-7446-1-10-20190706.pdf:pdf},
isbn = {9781577358091},
issn = {2374-3468},
journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
keywords = {L2L,NAS,RNN,architecture search,censoring,deep learning,evolution,evolutionary algorithms,genetic algorithms,image classification,learning to learn,learning-to-learn,meta learning,meta-learning,neural networks,neuro-evolution,neuroevolution,reinforcement,reinforcement learning,rl},
mendeley-tags = {RNN,censoring,deep learning},
month = {jul},
pages = {4798--4805},
title = {{Deep Recurrent Survival Analysis}},
url = {https://aaai.org/ojs/index.php/AAAI/article/view/4407},
volume = {33},
year = {2019}
}
@article{Steingrimsson2020,
abstract = {Deep learning is a class of machine learning algorithms that are popular for building risk prediction models. When observations are censored, the outcomes are only partially observed and standard deep learning algorithms cannot be directly applied. We develop a new class of deep learning algorithms for outcomes that are potentially censored. To account for censoring, the unobservable loss function used in the absence of censoring is replaced by a censoring unbiased transformation. The resulting class of algorithms can be used to estimate both survival probabilities and restricted mean survival. We show how the deep learning algorithms can be implemented by adapting software for uncensored data by using a form of response transformation. We provide comparisons of the proposed deep learning algorithms to existing risk prediction algorithms for predicting survival probabilities and restricted mean survival through both simulated datasets and analysis of data from breast cancer patients.},
annote = {History of deep survival analysis
time to event
right censoring ={\textgreater} Censoring unbiased loss functions12 (CULs) in deep learning: 
censoring unbiased deep learning (CUDL)

To overcome that challenge, Liao et al4 and Ranganath et al5proposed a deep learning algorithm where the loss function assumes a Weibull distributed failure time. Building on previous work,6 Katzman et al7 proposed a deep learning algorithm to estimate the functional form of the covariates in an underlying proportional hazard model using a loss function based on the partial likelihood of a proportional hazard model

={\textgreater} DeepSurv

===
KerasDeepLearning.R 
(Tensorflow)
from this article:
https://github.com/jonsteingrimsson/CensoringDL

the Keras interface to R. Keras is a high level application programming interface that incorporates various types of backend engines such as Tensorflow, CNTK, or Theano to train deep learning models.

==
DeepSurvK as well, using tensorflow},
author = {Steingrimsson, Jon Arni and Morrison, Samantha},
doi = {10.1002/sim.8542},
edition = {2020/04/13},
file = {:Users/texchi/Downloads/nihms-1586604.pdf:pdf},
issn = {1097-0258},
journal = {Statistics in medicine},
keywords = {CUDL,L2-loss,R,TFDeepSurv,censoring unbiased transformations,deep learning,doubly robust estimation,keras,machine learning,restricted mean survival,risk estimation,tensorflow},
language = {eng},
mendeley-tags = {CUDL,R,TFDeepSurv,deep learning,keras,tensorflow},
month = {jul},
number = {17},
pages = {2339--2349},
title = {{Deep learning for survival outcomes}},
url = {https://pubmed.ncbi.nlm.nih.gov/32281672 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7334068/ https://github.com/jonsteingrimsson/CensoringDL},
volume = {39},
year = {2020}
}
@article{Katzman2018,
abstract = {Medical practitioners use survival models to explore and understand the relationships between patients' covariates (e.g. clinical and genetic features) and the effectiveness of various treatment options. Standard survival models like the linear Cox proportional hazards model require extensive feature engineering or prior medical knowledge to model treatment interaction at an individual level. While nonlinear survival methods, such as neural networks and survival forests, can inherently model these high-level interaction terms, they have yet to be shown as effective treatment recommender systems.},
annote = {DeepSurv implements a deep learning generalization of the Cox proportional hazards model using Theano and Lasagne.
DeepSurv has an advantage over traditional Cox regression because it does not require an a priori selection of covariates, but learns them adaptively.
DeepSurv can be used in numerous survival analysis applications. One medical application is provided: recommend{\_}treatment, which provides treatment recommendations for a set of patient observations.


... DeepSurvK

DeepSurv is a Cox Proportional Hazards deep neural network used for modeling interactions between a patient's covariates and treatment effectiveness. It was originally proposed by Katzman et. al (2018) and implemented in Theano (using Lasagne).
Unfortunately, Theano is no longer supported. There have been some attempts in recreating DeepSurv in other DL platforms, such as czifan's DeepSurv.pytorch. However, given its popularity and ease of use, I think TensorFlow 2's Keras is a great option for this task.
mexchy1000 created DeepSurv{\_}Keras. However, it is a very raw prototype: it is not properly documented nor validated. Moreover, it is not being actively supported anymore. Therefore, I used it as a rough starting point for the development of DeepSurvK.

https://deepsurvk.readthedocs.io/en/latest/},
author = {Katzman, Jared L and Shaham, Uri and Cloninger, Alexander and Bates, Jonathan and Jiang, Tingting and Kluger, Yuval},
doi = {10.1186/s12874-018-0482-1},
file = {:Users/texchi/Downloads/s12874-018-0482-1.pdf:pdf},
issn = {1471-2288},
journal = {BMC Medical Research Methodology},
keywords = {deep learning,deepSurv},
mendeley-tags = {deep learning,deepSurv},
number = {1},
pages = {24},
title = {{DeepSurv: personalized treatment recommender system using a Cox proportional hazards deep neural network}},
url = {https://doi.org/10.1186/s12874-018-0482-1},
volume = {18},
year = {2018}
}
@article{Zhang2019,
abstract = {Logistic regression model is one of the most widely used modeling techniques in clinical medicine, owing to the widely available statistical packages for its implementation, and the ease of interpretation. However, logistic model training requires strict assumptions (such as additive and linearity) to be met and these assumptions may not hold true in real world. Thus, clinical investigators need to master some advanced model training methods that can predict more accurately. TensorFlow™ is a popular tool in training machine learning models such as supervised, unsupervised and reinforcement learning methods. Thus, it is important to learn TensorFlow™ in the era of big data. Since most clinical investigators are familiar with the logistic regression model, this article provides a step-by-step tutorial on how to train a logistic regression model in TensorFlow™, with the primary purpose to illustrate how the TensorFlow™ works. We first need to construct a graph with tensors and operations, then the graph is run in a session. Finally, we display the graph and summary statistics in the TensorBoard, which shows the changes of the accuracy and loss value across the training iterations.},
annote = {the installation of TensorFlow within R environment are available at https://tensorflow.rstudio.com/tensorflow/articles/installation.html.


* there is NO
Cox proportional hazards analyses;},
author = {Zhang, Zhongheng and Mo, Lei and Huang, Chen and Xu, Ping},
doi = {10.21037/atm.2019.09.125},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Zhang et al. - 2019 - Binary logistic regression modeling with TensorFlow™.pdf:pdf},
issn = {23055839},
journal = {Annals of Translational Medicine},
keywords = {Logistic regression,R,TensorFlow,gradient descent},
mendeley-tags = {Logistic regression,R,TensorFlow,gradient descent},
month = {oct},
number = {20},
pages = {591--591},
title = {{Binary logistic regression modeling with TensorFlow™}},
url = {http://atm.amegroups.com/article/view/30334/26367},
volume = {7},
year = {2019}
}
@article{Kim2019,
abstract = {The Cox proportional hazards model commonly used to evaluate prognostic variables in survival of cancer patients may be too simplistic to properly predict a cancer patient's outcome since it assumes that the outcome is a linear combination of covariates. In this retrospective study including 255 patients suitable for analysis who underwent surgical treatment in our department from 2000 to 2017, we applied a deep learning-based survival prediction method in oral squamous cell carcinoma (SCC) patients and validated its performance. Survival prediction using DeepSurv, a deep learning based-survival prediction algorithm, was compared with random survival forest (RSF) and the Cox proportional hazard model (CPH). DeepSurv showed the best performance among the three models, the c-index of the training and testing sets reaching 0.810 and 0.781, respectively, followed by RSF (0.770/0.764), and CPH (0.756/0.694). The performance of DeepSurv steadily improved with added features. Thus, deep learning-based survival prediction may improve prediction accuracy and guide clinicians both in choosing treatment options for better survival and in avoiding unnecessary treatments.},
annote = {Deep learning-based survival analysis
DeepSurv by Katzman et al. was implemented as an open-source Python module (https://github.com/jaredleekatzman/DeepSurv)16. 
DeepSurv is a multi-layer feed forward network, of which the output is a negative log partial likelihood, parameterized by the weights of the network. It is implemented in Theano with the Python package Lasagne. It also includes hyper-parameter optimization search. The source code is available at the above URL.

= concordance index
Harrell's c-index is known to be the most accurate and suitable method for estimating prediction error15. The c-index is used most commonly as a metric for survival prediction and reflects a measure of how well a model predicts the ordering of patients' death times. A c = 0.5 is the average of a random model, and c = 1 refers to a perfect match of death time ranking
==

comparing 3 algorisms:

Deep learning based-survival model, random survival forest (RSF), and CPH model were built and their performance compared with one another using Harrell's c-index.},
author = {Kim, Dong Wook and Lee, Sanghoon and Kwon, Sunmo and Nam, Woong and Cha, In-Ho and Kim, Hyung Jun},
doi = {10.1038/s41598-019-43372-7},
file = {:Users/texchi/Downloads/s41598-019-43372-7.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
keywords = {Cox,HNSCC,deep learning,deepSurv},
mendeley-tags = {Cox,HNSCC,deep learning,deepSurv},
number = {1},
pages = {6994},
title = {{Deep learning-based survival prediction of oral cancer patients}},
url = {https://doi.org/10.1038/s41598-019-43372-7},
volume = {9},
year = {2019}
}
@misc{Utkin2020,
abstract = {A new modification of the explanation method SurvLIME called SurvLIME-Inf for explaining machine learning survival models is proposed. The basic idea behind SurvLIME as well as SurvLIME-Inf is to apply the Cox proportional hazards model to approximate the black-box survival model at the local area around a test example. The Cox model is used due to the linear relationship of covariates. In contrast to SurvLIME, the proposed modification uses L∞-norm for defining distances between approximating and approximated cumulative hazard functions. This leads to a simple linear programming problem for determining important features and for explaining the black-box model prediction. Moreover, SurvLIME-Inf outperforms SurvLIME when the training set is very small. Numerical experiments with synthetic and real datasets demonstrate the SurvLIME-Inf efficiency.},
annote = {https://www.arxiv-vanity.com/papers/1602.04938/Local Interpretable Model-agnostic Explanations (LIME):
from},
archivePrefix = {arXiv},
arxivId = {cs.LG/2005.02387},
author = {Utkin, Lev V and Kovalev, Maxim S and Kasimov, Ernest M},
booktitle = {arXivLabs},
eprint = {2005.02387},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Utkin, Kovalev, Kasimov - 2020 - SurvLIME-Inf A simplified modification of SurvLIME for explanation of machine learning survival models.pdf:pdf},
keywords = {Cox proportional hazards model,GNN,LIME,SurvLIME,censoring,survival SurvLIME-Inf},
mendeley-tags = {Cox proportional hazards model,GNN,LIME,SurvLIME,censoring,survival SurvLIME-Inf},
primaryClass = {cs.LG},
title = {{SurvLIME-Inf: A simplified modification of SurvLIME for explanation of machine learning survival models}},
url = {https://arxiv.org/abs/2005.02387v1 https://www.arxiv-vanity.com/papers/2005.02387/},
urldate = {2020-11-30},
year = {2020}
}
@article{Wulczyn2020,
abstract = {Providing prognostic information at the time of cancer diagnosis has important implications for treatment and monitoring. Although cancer staging, histopathological assessment, molecular features, and clinical variables can provide useful prognostic insights, improving risk stratification remains an active research area. We developed a deep learning system (DLS) to predict disease specific survival across 10 cancer types from The Cancer Genome Atlas (TCGA). We used a weakly-supervised approach without pixel-level annotations, and tested three different survival loss functions. The DLS was developed using 9,086 slides from 3,664 cases and evaluated using 3,009 slides from 1,216 cases. In multivariable Cox regression analysis of the combined cohort including all 10 cancers, the DLS was significantly associated with disease specific survival (hazard ratio of 1.58, 95{\%} CI 1.28–1.70, p{\textless}0.0001) after adjusting for cancer type, stage, age, and sex. In a per-cancer adjusted subanalysis, the DLS remained a significant predictor of survival in 5 of 10 cancer types. Compared to a baseline model including stage, age, and sex, the c-index of the model demonstrated an absolute 3.7{\%} improvement (95{\%} CI 1.0–6.5) in the combined cohort. Additionally, our models stratified patients within individual cancer stages, particularly stage II (p = 0.025) and stage III (p{\textless}0.001). By developing and evaluating prognostic models across multiple cancer types, this work represents one of the most comprehensive studies exploring the direct prediction of clinical outcomes using deep learning and histopathology images. Our analysis demonstrates the potential for this approach to provide significant prognostic information in multiple cancer types, and even within specific pathologic stages. However, given the relatively small number of cases and observed clinical events for a deep learning task of this type, we observed wide confidence intervals for model performance, thus highlighting that future work will benefit from larger datasets assembled for the purposes for survival modeling.},
author = {Wulczyn, Ellery and Steiner, David and Xu, Zhaoyang and Sadhwani, Apaar and Wang, Hongwu and Flament, Isabelle and Mermel, Craig and Chen, Cameron and Liu, Yun and Stumpe, Martin},
file = {:Users/texchi/Downloads/journal.pone.0233678.pdf:pdf},
journal = {PLOS ONE},
keywords = {deep learning,google,survival},
mendeley-tags = {deep learning,google,survival},
title = {{Deep learning-based survival prediction for multiple cancer types using histopathology images}},
url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0233678},
year = {2020}
}
@article{Su2020,
abstract = {Detecting gene sets that serve as biomarkers for differentiating patient survival groups may help diagnose diseases robustly and develop multi-gene targeted therapies. However, due to the exponential growth of search space imposed by gene combinations, the performance of existing methods is still far from satisfactory. In this study, we developed a new method called BISG (BIclustering based Survival-related Gene sets detection) based on a rectified factor network (RFN) model, which allows efficiently biclustering gene subsets. By correlating genes in each significant bicluster with patient survival outcomes using a log-rank test and multi-sampling strategy, multiple survival-related gene sets can be detected. We applied BISG on three different cancer types, and the resulting gene sets were tested as biomarkers for survival analyses. Secondly, we systematically analyzed 12 different cancer datasets. Our analysis shows that the genes in all the survival-related gene sets are mainly from five gene families: microRNA protein coding host genes, zinc fingers C2H2-type, solute carriers, CD (cluster of differentiation) molecules, and ankyrin repeat domain containing genes. Moreover, we found that they are mainly enriched in heme metabolism, apoptosis, hypoxia and inflammatory response-related pathways. We compared BISG with two other methods, GSAS and IPSOV. Results show that BISG can better differentiate patient survival groups in different datasets. The identified biomarkers suggested by our study provide useful hypotheses for further investigation. BISG is publicly available with open source at https://github.com/LingtaoSu/BISG.},
author = {Su, Lingtao and Liu, Guixia and Wang, Juexin and Gao, Jianjiong and Xu, Dong},
doi = {10.3389/fbioe.2020.00349},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Su et al. - 2020 - Detecting Cancer Survival Related Gene Markers Based on Rectified Factor Network.pdf:pdf},
issn = {22964185},
journal = {Frontiers in Bioengineering and Biotechnology},
keywords = {ReLU,biclustering,biomarker,rectified factor network,survival analysis,variational inference},
mendeley-tags = {ReLU,biclustering},
pages = {349},
pmid = {32426342},
publisher = {Frontiers Media SA},
title = {{Detecting Cancer Survival Related Gene Markers Based on Rectified Factor Network}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/32426342 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC7212422},
volume = {8},
year = {2020}
}
@article{Li2019a,
abstract = {Deep learning, which is especially formidable in handling big data, has achieved great success in various fields, including bioinformatics. With the advances of the big data era in biology, it is foreseeable that deep learning will become increasingly important in the field and will be incorporated in vast majorities of analysis pipelines. In this review, we provide both the exoteric introduction of deep learning, and concrete examples and implementations of its representative applications in bioinformatics. We start from the recent achievements of deep learning in the bioinformatics field, pointing out the problems which are suitable to use deep learning. After that, we introduce deep learning in an easy-to-understand fashion, from shallow neural networks to legendary convolutional neural networks, legendary recurrent neural networks, graph neural networks, generative adversarial networks, variational autoencoder, and the most recent state-of-the-art architectures. After that, we provide eight examples, covering five bioinformatics research directions and all the four kinds of data type, with the implementation written in Tensorflow and Keras. Finally, we discuss the common issues, such as overfitting and interpretability, that users will encounter when adopting deep learning methods and provide corresponding suggestions. The implementations are freely available at https://github.com/lykaust15/Deep{\_}learning{\_}examples.},
author = {Li, Yu and Huang, Chao and Ding, Lizhong and Li, Zhongxiao and Pan, Yijie and Gao, Xin},
doi = {https://doi.org/10.1016/j.ymeth.2019.04.008},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Li et al. - 2019 - Deep learning in bioinformatics Introduction, application, and perspective in the big data era.pdf:pdf;:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Li et al. - 2019 - Deep learning in bioinformatics Introduction, application, and perspective in the big data era.docx:docx},
issn = {1046-2023},
journal = {Methods},
pages = {4--21},
title = {{Deep learning in bioinformatics: Introduction, application, and perspective in the big data era}},
url = {http://www.sciencedirect.com/science/article/pii/S1046202318303256},
volume = {166},
year = {2019}
}
@misc{rhee2018hybrid,
abstract = {Network biology has been successfully used to help reveal complex mechanisms of disease, especially cancer. On the other hand, network biology requires in-depth knowledge to construct disease-specific networks, but our current knowledge is very limited even with the recent advances in human cancer biology. Deep learning has shown a great potential to address the difficult situation like this. However, deep learning technologies conventionally use grid-like structured data, thus application of deep learning technologies to the classification of human disease subtypes is yet to be explored. Recently, graph based deep learning techniques have emerged, which becomes an opportunity to leverage analyses in network biology. In this paper, we proposed a hybrid model, which integrates two key components 1) graph convolution neural network (graph CNN) and 2) relation network (RN). We utilize graph CNN as a component to learn expression patterns of cooperative gene community, and RN as a component to learn associations between learned patterns. The proposed model is applied to the PAM50 breast cancer subtype classification task, the standard breast cancer subtype classification of clinical utility. In experiments of both subtype classification and patient survival analysis, our proposed method achieved significantly better performances than existing methods. We believe that this work is an important starting point to realize the upcoming personalized medicine.},
archivePrefix = {arXiv},
arxivId = {cs.CV/1711.05859},
author = {Rhee, Sungmin and Seo, Seokjun and Kim, Sun},
eprint = {1711.05859},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Rhee, Seo, Kim - 2018 - Hybrid Approach of Relation Network and Localized Graph Convolutional Filtering for Breast Cancer Subtype Classi.pdf:pdf},
keywords = {survival},
mendeley-tags = {survival},
primaryClass = {cs.CV},
title = {{Hybrid Approach of Relation Network and Localized Graph Convolutional Filtering for Breast Cancer Subtype Classification}},
year = {2018}
}
@inproceedings{Yu2020,
abstract = {e14057Background: This study aimed to investigate the prognostic value of transcriptome and clinical data of Hepatocellular carcinoma (HCC) patients for overall survival (OS) by deep learning method. Methods: A total of 371 HCC patients with 20530 level three RNA-sequencing data were from The Cancer Genome Atlas (TCGA). Cox-nnet model, a deep learning model through an artificial neural network extension of the Cox regression model, was used for OS prediction. The patients were randomly split into train-set and test-set (7:3). In train-set, the significant genes associated with OS under univariate Cox regression were considered for modeling. Clinical parameters, including age, gender, pathologic stage, child pugh classification, creatinine level etc. were also considered. The Cox-nnet model was developed by cross-validation. Its discrimination was determined by the concordance index (CI) in the independent test-set and compared with multivariable Cox regression. The clustering method Uniform Manifold Approximation and Projection (UMAP) was used for revealing biological information from the hidden layer in the model. Results: In the train-set (n = 259), 1505 genes and two clinical variables (child pugh score and creatinine level) were significantly associated with OS (adjusted P-value {\textless} 0.05). To avoid overfitting, only 40 most significant genes were included in the Cox-nnet model. In the test-set (n = 112), the CI of Cox-nnet (0.76, se = 0.04) is better than the CI of multivariable Cox regression (0.71, se = 0.05). The difference between good or poor survival subgroups classified by Cox-nnet was remarkably significant (P-value = 1e-4, median OS: 80.7 vs. 25.1 months). In the Cox-nnet model with all significant variables, the weights in the hidden layer were clustered by UMAP into 3 positive clusters and 2 negative clusters, which are enriched in GO/KEGG. The ?cell cycle? and ?complement and coagulation cascades? are the most important signal pathways in positive and negative clusters, respectively. Conclusions: Combining transcriptomic and clinical data, and with deep learning algorithm, we built and validated a robust model for survival prediction in HCC patients. Our study would be useful to explore the clinical implications in survival prediction and corresponding genetic mechanisms. Clinical trial information: 5U24CA143799, 5U24CA143835, 5U24CA143840, 5U24CA143843, 5U24CA143845, 5U24CA143848, 5U24CA1438.},
annote = {doi: 10.1200/JCO.2020.38.15{\_}suppl.e14057},
author = {Yu, Hao and Dai, Wei and Chiang, Chi Leung and Du, Shisuo and Zeng, Zhao-Chong and Shi, Guo-Ming and Zhang, Wei and Chan, Albert and Hu, Chen and Kong, Feng-Ming},
booktitle = {Journal of Clinical Oncology},
doi = {10.1200/JCO.2020.38.15_suppl.e14057},
issn = {0732-183X},
month = {may},
number = {15{\_}suppl},
pages = {e14057--e14057},
publisher = {Wolters Kluwer},
title = {{Deep learning to develop transcriptomic model for survival prediction in TCGA patients with hepatocellular carcinoma.}},
url = {https://doi.org/10.1200/JCO.2020.38.15{\_}suppl.e14057},
volume = {38},
year = {2020}
}
@article{Padilha2017,
abstract = {Background: Biclustering techniques are capable of simultaneously clustering rows and columns of a data matrix. These techniques became very popular for the analysis of gene expression data, since a gene can take part of multiple biological pathways which in turn can be active only under specific experimental conditions. Several biclustering algorithms have been developed in the past recent years. In order to provide guidance regarding their choice, a few comparative studies were conducted and reported in the literature. In these studies, however, the performances of the methods were evaluated through external measures that have more recently been shown to have undesirable properties. Furthermore, they considered a limited number of algorithms and datasets. Results: We conducted a broader comparative study involving seventeen algorithms, which were run on three synthetic data collections and two real data collections with a more representative number of datasets. For the experiments with synthetic data, five different experimental scenarios were studied: different levels of noise, different numbers of implanted biclusters, different levels of symmetric bicluster overlap, different levels of asymmetric bicluster overlap and different bicluster sizes, for which the results were assessed with more suitable external measures. For the experiments with real datasets, the results were assessed by gene set enrichment and clustering accuracy. Conclusions: We observed that each algorithm achieved satisfactory results in part of the biclustering tasks in which they were investigated. The choice of the best algorithm for some application thus depends on the task at hand and the types of patterns that one wants to detect.},
author = {Padilha, Victor A. and Campello, Ricardo J.G.B.},
doi = {10.1186/s12859-017-1487-1},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Padilha, Campello - 2017 - A systematic comparative evaluation of biclustering techniques.pdf:pdf},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Biclustering,Clustering,Gene expression,biclustering},
mendeley-tags = {biclustering},
month = {dec},
number = {1},
pages = {55},
pmid = {28114903},
publisher = {BioMed Central},
title = {{A systematic comparative evaluation of biclustering techniques}},
url = {http://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-017-1487-1},
volume = {18},
year = {2017}
}
@article{Zhao2020,
abstract = {Background: Cancer of unknown primary (CUP), representing approximately 3-5{\%} of all malignancies, is defined as metastatic cancer where a primary site of origin cannot be found despite a standard diagnostic workup. Because knowledge of a patient's primary cancer remains fundamental to their treatment, CUP patients are significantly disadvantaged and most have a poor survival outcome. Developing robust and accessible diagnostic methods for resolving cancer tissue of origin, therefore, has significant value for CUP patients. Methods: We developed an RNA-based classifier called CUP-AI-Dx that utilizes a 1D Inception convolutional neural network (1D-Inception) model to infer a tumor's primary tissue of origin. CUP-AI-Dx was trained using the transcriptional profiles of 18,217 primary tumours representing 32 cancer types from The Cancer Genome Atlas project (TCGA) and International Cancer Genome Consortium (ICGC). Gene expression data was ordered by gene chromosomal coordinates as input to the 1D-CNN model, and the model utilizes multiple convolutional kernels with different configurations simultaneously to improve generality. The model was optimized through extensive hyperparameter tuning, including different max-pooling layers and dropout settings. For 11 tumour types, we also developed a random forest model that can classify the tumour's molecular subtype according to prior TCGA studies. The optimised CUP-AI-Dx tissue of origin classifier was tested on 394 metastatic samples from 11 tumour types from TCGA and 92 formalin-fixed paraffin-embedded (FFPE) samples representing 18 cancer types from two clinical laboratories. The CUP-AI-Dx molecular subtype was also independently tested on independent ovarian and breast cancer microarray datasets Findings: CUP-AI-Dx identifies the primary site with an overall top-1-accuracy of 98.54{\%} in cross-validation and 96.70{\%} on a test dataset. When applied to two independent clinical-grade RNA-seq datasets generated from two different institutes from the US and Australia, our model predicted the primary site with a top-1-accuracy of 86.96{\%} and 72.46{\%} respectively. Interpretation: The CUP-AI-Dx predicts tumour primary site and molecular subtype with high accuracy and therefore can be used to assist the diagnostic work-up of cancers of unknown primary or uncertain origin using a common and accessible genomics platform. Funding: NIH R35 GM133562, NCI P30 CA034196, Victorian Cancer Agency Australia.},
author = {Zhao, Yue and Pan, Ziwei and Namburi, Sandeep and Pattison, Andrew and Posner, Atara and Balachander, Shiva and Paisie, Carolyn A. and Reddi, Honey V. and Rueter, Jens and Gill, Anthony J. and Fox, Stephen and Raghav, Kanwal P.S. and Flynn, William F. and Tothill, Richard W. and Li, Sheng and Karuturi, R. Krishna Murthy and George, Joshy},
doi = {10.1016/j.ebiom.2020.103030},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Zhao et al. - 2020 - CUP-AI-Dx A tool for inferring cancer tissue of origin and molecular subtype using RNA gene-expression data and art.pdf:pdf},
issn = {23523964},
journal = {EBioMedicine},
keywords = {Cancer,Cancer-of-unknown-primary,Cell-of-origin,Classification,Convolutional neural network,Deep learning,Inception model,Machine learning,TCGA},
pmid = {33039710},
publisher = {Elsevier B.V.},
title = {{CUP-AI-Dx: A tool for inferring cancer tissue of origin and molecular subtype using RNA gene-expression data and artificial intelligence}},
volume = {61},
year = {2020}
}
@article{Han2018,
abstract = {A key step in understanding the spatial organization of cells and tissues is the ability to construct generative models that accurately reflect that organization. In this paper, we focus on building generative models of electron microscope (EM) images in which the positions of cell membranes and mitochondria have been densely annotated, and propose a two-stage procedure that produces realistic images using Generative Adversarial Networks (or GANs) in a supervised way. In the first stage, we synthesize a label "image" given a noise "image" as input, which then provides supervision for EM image synthesis in the second stage. The full model naturally generates label-image pairs. We show that accurate synthetic EM images are produced using assessment via (1) shape features and global statistics, (2) segmentation accuracies, and (3) user studies. We also demonstrate further improvements by enforcing a reconstruction loss on intermediate synthetic labels and thus unifying the two stages into one single end-to-end framework.},
author = {Han, Ligong and Murphy, Robert F and Ramanan, Deva},
doi = {10.1109/WACV.2018.00080},
edition = {2018/05/07},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Han, Murphy, Ramanan - 2018 - Learning Generative Models of Tissue Organization with Supervised GANs.pdf:pdf},
issn = {2472-6737},
journal = {IEEE Winter Conference on Applications of Computer Vision. IEEE Winter Conference on Applications of Computer Vision},
keywords = {GAN},
language = {eng},
mendeley-tags = {GAN},
month = {mar},
pages = {682--690},
pmid = {30177974},
title = {{Learning Generative Models of Tissue Organization with Supervised GANs}},
url = {https://pubmed.ncbi.nlm.nih.gov/30177974 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6119234/},
volume = {2018},
year = {2018}
}
@article{Rietschel2019,
abstract = {Deep learning models for survival analysis have gained significant attention in the literature, but they suffer from severe performance deficits when the dataset contains many irrelevant features. We give empirical evidence for this problem in real-world medical settings using the state-of-the-art model DeepHit. Furthermore, we develop methods to improve the deep learning model through novel approaches to feature selection in survival analysis. We propose filter methods for hard feature selection and a neural network architecture that weights features for soft feature selection. Our experiments on two real-world medical datasets demonstrate that substantial performance improvements against the original models are achievable.},
annote = {https://github.com/texchi2/deephitplus
DeepHit+, python code available on github},
archivePrefix = {arXiv},
arxivId = {1811.09317v4},
author = {Rietschel, Carl and Yoon, Jinsung and van der Schaar, Mihaela},
eprint = {1811.09317v4},
file = {:Users/texchi/Downloads/1811.09317v4.pdf:pdf},
journal = {arXiv},
keywords = {DeepHit},
mendeley-tags = {DeepHit},
title = {{Feature Selection for Survival Analysis with Competing Risks using Deep Learning}},
url = {https://arxiv.org/abs/1811.09317v4},
year = {2019}
}
@article{MoradiFard2020,
abstract = {We study in this paper the problem of jointly clustering and learning representations. As several previous studies have shown, learning representations that are both faithful to the data to be clustered and adapted to the clustering algorithm can lead to better clustering performance, all the more so that the two tasks are performed jointly. We propose here such an approach for k-Means clustering based on a continuous reparametrization of the objective function that leads to a truly joint solution. The behavior of our approach is illustrated on various datasets showing its efficacy in learning representations for objects while clustering them.},
author = {{Moradi Fard}, Maziar and Thonet, Thibaut and Gaussier, Eric},
doi = {https://doi.org/10.1016/j.patrec.2020.07.028},
file = {:Users/texchi/Downloads/1-s2.0-S0167865520302749-main.pdf:pdf},
issn = {0167-8655},
journal = {Pattern Recognition Letters},
keywords = {Clustering,Deep clustering,Deep learning,deep clustering; k-Means; deep learning; clustering,k-Means},
mendeley-tags = {deep clustering; k-Means; deep learning; clustering},
pages = {185--192},
title = {{Deep k-Means: Jointly clustering with k-Means and learning representations}},
url = {http://www.sciencedirect.com/science/article/pii/S0167865520302749},
volume = {138},
year = {2020}
}
@article{Schmauch2020,
abstract = {Deep learning methods for digital pathology analysis are an effective way to address multiple clinical questions, from diagnosis to prediction of treatment outcomes. These methods have also been used to predict gene mutations from pathology images, but no comprehensive evaluation of their potential for extracting molecular features from histology slides has yet been performed. We show that HE2RNA, a model based on the integration of multiple data modes, can be trained to systematically predict RNA-Seq profiles from whole-slide images alone, without expert annotation. Through its interpretable design, HE2RNA provides virtual spatialization of gene expression, as validated by CD3- and CD20-staining on an independent dataset. The transcriptomic representation learned by HE2RNA can also be transferred on other datasets, even of small size, to increase prediction performance for specific molecular phenotypes. We illustrate the use of this approach in clinical diagnosis purposes such as the identification of tumors with microsatellite instability.},
annote = {Preprocessing of whole-slide images. The application of deep-learning algo- rithms to histological data is a challenging problem, particularly due to the high dimensionality of the data (up to 100,000 × 100,000 pixels for a single whole-slide image) and the small size of available datasets. We divided the whole-slide images into squares of 112 × 112 $\mu$m (224 × 224 pixels) called “tiles”, and used the Otsu algorithm62 (as implemented in python package skimage) to select only those containing tissue, excluding the white background. We sampled a maximum of 8000 such tiles from each slide. We then extracted 2048 features from those tiles with a 50-layer ResNet63 pretrained on the ImageNet dataset64 (using the Keras implementation), such that a slide could be represented as a 8000 × 2048 matrix. 
For the first phase of this work (transcriptome prediction), we accelerated the training of our models through a simple preprocessing step inspired by simple linear iterative clustering (SLIC)65: we used the k-means algorithm (as implemented in python package libkmcuda) to create 100 clusters (supertiles) of tiles on the basis of tile location on the slide, and we averaged the features of the tiles within each cluster. The use of these supertiles reduces the dimensions of a slide to 100 × 2048. The model was first trained on this reduced dataset, with all the TCGA data. Then, for specific organs, fine-tuning was achieved with full-scale data from the organs concerned only.


==
Haider, S. {\&} Pal, R. Integrated analysis of transcriptomic and proteomic data. Curr. Genomics. 2, 91–110 (2013).
={\textgreater} Recent studies have shown that mRNA and protein expressions may be poorly correlated due to various factors, such as different half-lives and post-transcription machinery.},
author = {Schmauch, Beno{\^{i}}t and Romagnoni, Alberto and Pronier, Elodie and Saillard, Charlie and Maill{\'{e}}, Pascale and Calderaro, Julien and Kamoun, Aur{\'{e}}lie and Sefta, Meriem and Toldo, Sylvain and Zaslavskiy, Mikhail and Clozel, Thomas and Moarii, Matahi and Courtiol, Pierre and Wainrib, Gilles},
doi = {10.1038/s41467-020-17678-4},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Schmauch et al. - 2020 - A deep learning model to predict RNA-Seq expression of tumours from whole slide images.pdf:pdf},
issn = {2041-1723},
journal = {Nature Communications},
keywords = {TCIA,deep learning,reproducibility},
mendeley-tags = {TCIA,deep learning,reproducibility},
number = {1},
pages = {3877},
title = {{A deep learning model to predict RNA-Seq expression of tumours from whole slide images}},
url = {https://doi.org/10.1038/s41467-020-17678-4},
volume = {11},
year = {2020}
}
@software{Wagner2020,
abstract = {This model package contains the R codes for Windows of the image segmentation algorithm called U-net used in the article. As I don't own the rights to publish the original very high resolution images, this example was made with a simulated image of WorldView of the same resolution than the original data. The simulated objects to segment are red noisy blobs (with similar size as trees) on a noisy green background (see in the directory ("./data-raw/train"). This code version works with TensorFlow 2 and most of the code is based on an adaptation of the original codes for segmentation with Unet published on the RStudio AI Blog here: https://blogs.rstudio.com/ai/posts/2019-08-23-unet/. To run the model, it is assumed that you have a computer with GPU sufficient to run deep learning models (CUDA compute capacity {\textgreater}3.0), and Rstudio with the package keras already working (https://keras.rstudio.com/). The model validation accuracy starts to increase after {\~{}}10 to 20 epochs. After {\~{}}55 epochs, the validation accuracy is {\textgreater}0.95 and reach 0.9957{\%} at epoch 100. On my computer, one epoch runs in 7s. The R codes and the simulated data are distributed in a .zip of {\~{}}136.4 Mb. The RGB images are in the directory "./data-raw/train" and the labelled mask of the objects (0=background, 1=object) are in the directory "./data-raw/train{\_}masks". Pretrained weights for 100 epochs are found in the directory "./weights{\_}saved". The model was run with the following libraries: Python 3.7.6, RStudio Version 1.3.959, R version 4.0.2 (2020-06-22), R keras package version 2.3.0.0.9000, tensorflow version 2.2.0-rc4, tensorflow{\_}addons version 0.10.0 and a Nvidia GeForce RTX 2080 (driver 451.48, CUDA 10.1 and cuDNN version 7.6.5.32). When using this dataset, please cite the original article : https://doi.org/10.1371/journal.pone.0229448. To install all requirements to run TensorFlow-2 within Rstudio on Windows see the manual here : https://zenodo.org/record/3929710},
author = {Wagner, Fabien Hubert},
doi = {10.5281/zenodo.3926822},
keywords = {DeepSurvK,tensorflow},
mendeley-tags = {DeepSurvK,tensorflow},
month = {jan},
publisher = {Zenodo},
title = {{Model package from: Mapping Atlantic rainforest degradation and regeneration history with indicator species using convolutional network}},
url = {https://doi.org/10.5281/zenodo.3926822},
year = {2020}
}
@misc{Chai2019,
abstract = {Motivation: Accurately predicting cancer prognosis is necessary to choose precise strategies of treatment for patients. One of effective approaches in the prediction is the integration of multi-omics data, which reduces the impact of noise within single omics data. However, integrating multi-omics data brings large number of redundant variables and relative small sample sizes. In this study, we employed Autoencoder networks to extract important features that were then input to the proportional hazards model to predict the cancer prognosis. Results: The method was applied to 12 common cancers from the Cancer Genome Atlas. The results show that the multi-omics averagely improves 4.1{\%} C-index for prognosis prediction over single mRNA data, and our method outperforms previous approaches by at least 7.4{\%}. A comparison of the contribution of single omics data show that mRNA contributes the most, followed by the DNA methylation, miRNA, and the copy number variation. In the case study for differential gene expression analysis, we identified 161 differentially expressed genes in the cervical cancer, among which 77 genes (65.8{\%}) have been proven to be associated with cancer. In addition, we performed the cross-cancer test where the model trained on one cancer was used to predict the prognosis of another cancer, and found 23 pairs of cancers have a C-index larger than 0.5, with the largest value of 0.68. Thus, this study has provided a deep learning framework to effectively integrate multiple omics data to predict cancer prognosis.},
author = {Chai, Hua and Zhou, Xiang and Cui, Zifeng and Rao, Jiahua and Hu, Zheng and Lu, Yutong and Zhao, Huiying and Yang, Yuedong},
booktitle = {bioRxiv},
doi = {10.1101/807214},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Chai et al. - 2019 - Integrating multi-omics data with deep learning for predicting cancer prognosis.pdf:pdf},
keywords = {XGBoost},
mendeley-tags = {XGBoost},
month = {oct},
publisher = {bioRxiv},
title = {{Integrating multi-omics data with deep learning for predicting cancer prognosis}},
year = {2019}
}
@misc{Dalagnol2020,
author = {Dalagnol, Ricardo and Wagner, Fabien},
doi = {10.5281/zenodo.3929710},
file = {:Users/texchi/Downloads/Install{\_}guide{\_}Tensorflow{\_}Keras{\_}in{\_}Rstudio.pdf:pdf},
month = {jul},
publisher = {Zenodo},
title = {{Tensorflow and Keras installation steps for Deep Learning applications in Rstudio}},
url = {https://doi.org/10.5281/zenodo.3929710},
urldate = {2020-11-07},
year = {2020}
}
@article{Fu2020,
abstract = {This is an editorial report of the supplements to BMC Bioinformatics that includes 6 papers selected from the BIOCOMP'19—The 2019 International Conference on Bioinformatics and Computational Biology. These articles reflect current trend and development in bioinformatics research.},
author = {Fu, Yuanyuan and Ling, Zhougui and Arabnia, Hamid and Deng, Youping},
doi = {10.1186/s12859-020-03874-y},
file = {:Users/texchi/Downloads/s12859-020-03874-y.pdf:pdf},
issn = {1471-2105},
journal = {BMC Bioinformatics},
number = {9},
pages = {538},
title = {{Current trend and development in bioinformatics research}},
url = {https://doi.org/10.1186/s12859-020-03874-y},
volume = {21},
year = {2020}
}
@article{Gerds2013,
abstract = {Given a predictive marker and a time-to-event response variable, the proportion of concordant pairs in a data set is called concordance index. A specifically useful marker is the risk predicted by a survival regression model. This article extends the existing methodology for applications where the length of the follow-up period depends on the predictor variables. A class of inverse probability of censoring weighted estimators is discussed in which the estimates rely on a working model for the conditional censoring distribution. The estimators are consistent for a truncated concordance index if the working model is correctly specified and if the probability of being uncensored at the truncation time is positive. In this framework, all kinds of prediction models can be assessed, and time trends in the discrimination ability of a model can be captured by varying the truncation time point. For illustration, we re-analyze a study on risk prediction for prostate cancer patients. The effects of misspecification of the censoring model are studied in simulated data. Copyright ? 2012 John Wiley {\&} Sons, Ltd.},
annote = {https://doi.org/10.1002/sim.5681},
author = {Gerds, Thomas A and Kattan, Michael W and Schumacher, Martin and Yu, Changhong},
doi = {https://doi.org/10.1002/sim.5681},
file = {:Users/texchi/Downloads/gerds2012.pdf:pdf},
issn = {0277-6715},
journal = {Statistics in Medicine},
keywords = {censored data,concordance index,deep learning,discrimination,inverse probability of censoring weighting,prediction models,survi,survival analysis},
mendeley-tags = {concordance index,deep learning,survi},
month = {jun},
number = {13},
pages = {2173--2184},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Estimating a time-dependent concordance index for survival prediction models with covariate dependent censoring}},
url = {https://doi.org/10.1002/sim.5681},
volume = {32},
year = {2013}
}
@misc{Kauke2018,
abstract = {Objectives: Therapeutic assessment of odontogenic myxoma (OM) is poorly standardized. Unidimensional size criteria have shown to be unreliable in therapeutic decision-making. We evaluate the size distribution of OM and scan for associated clinicoradiological signs of aggressiveness. Additionally, we evaluate three-dimensional size delineation of OM aiming to improve future therapeutic assessment of this destructive neoplasm. Methods: Primarily, we reviewed the database "PubMed" for data concerning the size of OMs as radiologically determined. Afterwards, the impact of age, sex, locularity and location on the size was investigated by $\chi$2 test, Student's t-test and regression analysis. Furthermore, we statistically evaluated the impact of size on the occurrence of clinicoradiological signs of aggressiveness. Secondly, we approximated the volume of five unpublished cases of OM by semi-automatic image segmentation of cone-beam CT images. Results: Multilocular OMs were significantly larger than unilocular ones (p {\textless} 0.002). Age (0.042) and multilocularity ({\textless}0.002) significantly impacted size. Size was significantly associated with cortical perforation (0.032) and multilocularity ({\textless}0.002), further regression analysis revealed tooth resorption (0.019), cortical perforation (0.005) and multilocularity ({\textless}0.002) as significant predictors of size. Employing the volume as a mean of comparison, we found that the biggest OM (38.42 ml; multilocular) was 124 times larger than the smallest (0.31 ml; unilocular). However, using the maximum diameter (cm) as a surrogate for size, the biggest lesion (6.3) was only 5.25 times larger than the smallest (1.2). Conclusions: Locularity and volumetric size characterization might help in therapeutic decisionmaking and could help to improve our understanding of OM.},
author = {Kauke, Martin and Safi, Ali Farid and Kreppel, Matthias and Grandoch, Andrea and Nickenig, Hans Joachim and Z{\"{o}}ller, Joachim E. and Dreiseidler, Timo},
booktitle = {Dentomaxillofacial Radiology},
doi = {10.1259/dmfr.20170262},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Kauke et al. - 2018 - Size distribution and clinicoradiological signs of aggressiveness in odontogenic myxoma-three-dimensional analysis.pdf:pdf},
issn = {0250832X},
keywords = {Image segmentation,Odontogenic myxoma,Size,Therapy,Volumetric analysis},
number = {2},
pmid = {29082773},
publisher = {British Institute of Radiology},
title = {{Size distribution and clinicoradiological signs of aggressiveness in odontogenic myxoma-three-dimensional analysis and systematic review}},
volume = {47},
year = {2018}
}
@misc{Chrcanovic2018,
abstract = {Objective: To integrate the available data published on glandular odontogenic cyst (GOC) into a comprehensive analysis of its clinical/radiological and histopathological features. Methods: An electronic search was undertaken in May/2017. Eligibility criteria included publications having enough clinical/radiological/histological information to confirm the diagnosis. Results: Fifty-eight publications (169 GOCs) were included. The lesion was slightly more prevalent in men than in women. There was a high prevalence in the fifty/sixth decades of life, in the anterior regions, and in mandibles. Lesions were commonly associated with bone expansion (73{\%}) and unilocular radiological appearance (61.5{\%}). GOC was found to be associated with tooth displacement or an unerupted tooth (30.9{\%}), cortical bone perforation (26{\%}), presence of clinical symptoms (24.3{\%}), root resorption (13.9{\%}). Microscopic parameters most commonly were observed in GOCs—in at least 95{\%} of the lesions: presence of hobnail cells, intraepithelial microcysts, epithelial lining with variable thickness. The presence of apocrine snouting was the microscopic parameter less often found (40.4{\%}). Conclusion: Although the recurrence rate of GOCs is not as high as previously believed, it is a relevant phenomenon (21.6{\%}). Adjunctive procedures after enucleation should be considered. None of the clinical/radiological and histopathological features evaluated had a statistically significant effect on the recurrence rate.},
author = {Chrcanovic, B. R. and Gomez, R. S.},
booktitle = {Oral Diseases},
doi = {10.1111/odi.12719},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Chrcanovic, Gomez - 2018 - Glandular odontogenic cyst An updated analysis of 169 cases reported in the literature.pdf:pdf},
issn = {16010825},
keywords = {clinical features,glandular odontogenic cyst,odontogenic cysts,recurrence rate},
month = {jul},
number = {5},
pages = {717--724},
pmid = {28744957},
publisher = {Blackwell Publishing Ltd},
title = {{Glandular odontogenic cyst: An updated analysis of 169 cases reported in the literature}},
volume = {24},
year = {2018}
}
@article{Liu2020,
abstract = {Electronic health records (EHRs) have been widely used to help physicians to make decisions by predicting medical events such as diseases, prescriptions, outcomes, and so on. How to represent patient longitudinal medical data is the key to making these predictions. Recurrent neural network (RNN) is a popular model for patient longitudinal medical data representation from the view of patient status sequences, but it cannot represent complex interactions among different types of medical information, i.e., temporal medical event graphs, which can be represented by graph neural network (GNN). In this paper, we propose a hybrid method of RNN and GNN, called RGNN, for next-period prescription prediction from two views, where RNN is used to represent patient status sequences, and GNN is used to represent temporal medical event graphs. Experiments conducted on the public MIMIC-III ICU data show that the proposed method is effective for next-period prescription prediction, and RNN and GNN are mutually complementary.},
annote = {Graph neural network (GNN) is a kind of deep neural network powerful for complex graphs [23]. Several methods are recently proposed to compute representations of nodes, edges, and graphs [24,25,26]. Among them, Graph Convolutional Network (GCN) that computes the representation of a node recursively from its neighbors is the most common one [27] and is widely applied to many domains such as natural language processing and knowledge graph representation. In the medical domain, GCN starts to be applied to many tasks. For example, Choi et al.'s deployed GCN to learn medical concept representations from the graph of medical ontology knowledge [28]. Ma et al.'s recognized the drug–drug interaction (DDI) problem as a graph classification problem and solve it by GCN [29]. Besides GCN, some other GNNs also have been proposed recently such as GAMENet [30] and Decagon [31]. GAMENet is a Graph Augmented Memory Network designed to integrate the DDI knowledge graph for the personalized recommendation of medication combination. Decagon is a multi-modal GNN for drug side effect prediction.

={\textgreater} Decagon
Zitnik M, Agrawal M, Leskovec J (2018) Modeling polypharmacy side effects with graph convolutional networks. Bioinformatics 34:i457–i466. https://doi.org/10.1093/bioinformatics/bty294},
author = {Liu, Sicen and Li, Tao and Ding, Haoyang and Tang, Buzhou and Wang, Xiaolong and Chen, Qingcai and Yan, Jun and Zhou, Yi},
doi = {10.1007/s13042-020-01155-x},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Liu et al. - 2020 - A hybrid method of recurrent neural network and graph neural network for next-period prescription prediction.pdf:pdf},
issn = {1868-808X},
journal = {International Journal of Machine Learning and Cybernetics},
keywords = {GNN},
mendeley-tags = {GNN},
number = {12},
pages = {2849--2856},
title = {{A hybrid method of recurrent neural network and graph neural network for next-period prescription prediction}},
url = {https://doi.org/10.1007/s13042-020-01155-x},
volume = {11},
year = {2020}
}
@article{Rendleman2019,
abstract = {Background: In the era of precision oncology and publicly available datasets, the amount of information available for each patient case has dramatically increased. From clinical variables and PET-CT radiomics measures to DNA-variant and RNA expression profiles, such a wide variety of data presents a multitude of challenges. Large clinical datasets are subject to sparsely and/or inconsistently populated fields. Corresponding sequencing profiles can suffer from the problem of high-dimensionality, where making useful inferences can be difficult without correspondingly large numbers of instances. In this paper we report a novel deployment of machine learning techniques to handle data sparsity and high dimensionality, while evaluating potential biomarkers in the form of unsupervised transformations of RNA data. We apply preprocessing, MICE imputation, and sparse principal component analysis (SPCA) to improve the usability of more than 500 patient cases from the TCGA-HNSC dataset for enhancing future oncological decision support for Head and Neck Squamous Cell Carcinoma (HNSCC). Results: Imputation was shown to improve prognostic ability of sparse clinical treatment variables. SPCA transformation of RNA expression variables reduced runtime for RNA-based models, though changes to classifier performance were not significant. Gene ontology enrichment analysis of gene sets associated with individual sparse principal components (SPCs) are also reported, showing that both high- and low-importance SPCs were associated with cell death pathways, though the high-importance gene sets were found to be associated with a wider variety of cancer-related biological processes. Conclusions: MICE imputation allowed us to impute missing values for clinically informative features, improving their overall importance for predicting two-year recurrence-free survival by incorporating variance from other clinical variables. Dimensionality reduction of RNA expression profiles via SPCA reduced both computation cost and model training/evaluation time without affecting classifier performance, allowing researchers to obtain experimental results much more quickly. SPCA simultaneously provided a convenient avenue for consideration of biological context via gene ontology enrichment analysis.},
annote = {https://github.com/mrendleman/MachineLearningTCGAHNSC-BINF/},
author = {Rendleman, Michael C. and Buatti, John M. and Braun, Terry A. and Smith, Brian J. and Nwakama, Chibuzo and Beichel, Reinhard R. and Brown, Bart and Casavant, Thomas L.},
doi = {10.1186/s12859-019-2929-8},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Rendleman et al. - 2019 - Machine learning with the TCGA-HNSC dataset improving usability by addressing inconsistency, sparsity, and hig.pdf:pdf},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Decision support,Dimensionality reduction,Gene ontology enrichment analysis,Machine learning,RNA-seq,Unsupervised transformation,hnscc,random forest,survival imputation,tcga},
mendeley-tags = {RNA-seq,random forest,survival imputation},
month = {dec},
number = {1},
pages = {339},
pmid = {31208324},
publisher = {BioMed Central},
title = {{Machine learning with the TCGA-HNSC dataset: Improving usability by addressing inconsistency, sparsity, and high-dimensionality}},
url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-2929-8},
volume = {20},
year = {2019}
}
@misc{kong2018graphembedded,
abstract = {Gene expression data represents a unique challenge in predictive model building, because of the small number of samples (n) compared to the huge amount of features (p). This "n{\textless}{\textless}p" property has hampered application of deep learning techniques for disease outcome classification. Sparse learning by incorporating external gene network information could be a potential solution to this issue. Still, the problem is very challenging because (1) there are tens of thousands of features and only hundreds of training samples, (2) the scale-free structure of the gene network is unfriendly to the setup of convolutional neural networks. To address these issues and build a robust classification model, we propose the Graph-Embedded Deep Feedforward Networks (GEDFN), to integrate external relational information of features into the deep neural network architecture. The method is able to achieve sparse connection between network layers to prevent overfitting. To validate the method's capability, we conducted both simulation experiments and a real data analysis using a breast cancer RNA-seq dataset from The Cancer Genome Atlas (TCGA). The resulting high classification accuracy and easily interpretable feature selection results suggest the method is a useful addition to the current classification models and feature selection procedures. The method is available at https://github.com/yunchuankong/GEDFN},
annote = {https://github.com/yunchuankong/GEDFN
https://github.com/yunchuankong/NetworkNeuralNetwork

=

supplement
https://oup.silverchair-cdn.com/oup/backfile/Content{\_}public/Journal/bioinformatics/34/21/10.1093{\_}bioinformatics{\_}bty429/1/bty429{\_}supporting{\_}file.pdf?Expires=1608280474{\&}Signature=EnAcJsOIcH4wCD25lkNRRjG7{\~{}}laTUpomvID7C2EIYEMoI3qFdcpbGCHOAwtg{\~{}}ZewJ7iRgGI{\~{}}b4d-Xbdoq7HV2iIei4-7VFgsQkCRxHTsT{\~{}}ihIkn5kdrVIXqT2X8CU2o2Fuoak0C4{\~{}}2PLmR9gUg1CCcE8t0MbzQZL4vx-3kds0TajHcZAQhqhNyHhceNr50pAUmhrUwijm9y6Gdvv3qQCxLXRdZI-VhDmbiMFR5-ZDaSUB8Cfer4i{\~{}}3VUAl7uHCxB9UUjXfCC4JSeinqZaEdDefoGNpIPcrbvvQKyHatELNfnzuNA87gxtBu2AUkLyJHfSH6Hu9{\~{}}EByhmPPst99jrZg{\_}{\_}{\&}Key-Pair-Id=APKAIE5G5CRDK6RD3PGA},
archivePrefix = {arXiv},
arxivId = {stat.ML/1801.06202},
author = {Kong, Yunchuan and Yu, Tianwei},
doi = {10.1093/bioinformatics/bty429},
eprint = {1801.06202},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Kong, Yu - 2018 - A graph-embedded deep feedforward network for disease outcome classification and feature selection using gene expressi.pdf:pdf;:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Kong, Yu - 2018 - A graph-embedded deep feedforward network for disease outcome classification and feature selection using gene express.docx:docx},
keywords = {GEDFN,Graph,RNA-seq,TCGA,Tensorflow,deep learning},
mendeley-tags = {GEDFN,Graph,RNA-seq,TCGA,Tensorflow,deep learning},
primaryClass = {stat.ML},
title = {{A graph-embedded deep feedforward network for disease outcome classification and feature selection using gene expression data}},
url = {https://academic.oup.com/bioinformatics/article/34/21/3727/5021680 https://oup.silverchair-cdn.com/oup/backfile/Content{\_}public/Journal/bioinformatics/34/21/10.1093{\_}bioinformatics{\_}bty429/1/bty429{\_}supporting{\_}file.pdf?Expires=1608280474{\&}Signature=EnAcJsOIcH4},
year = {2018}
}
@article{Kaffe1997,
abstract = {Objectives: To analyse critically the clinical and radiological features of odontogenic myxoma. Method: The clinical features of 164 cases of odontogenic myxoma (two new and 162 from the literature) and the radiological features of 96 cases (two new and 94 from the literature) were analysed. Results: Most of the tumors (75{\%}) were diagnosed in the 2nd to 4th decades. The male to female ratio was 1 : 1.5. Tumors were located in the mandible in two-thirds and in the maxilla one-third of cases. A multilocular appearance was observed in 55{\%} and unilocular in 36{\%}: 9{\%} were not loculated. There was a statistically significant correlation (P{\textless}0.000) between the size of the lesion and its locularity with the larger lesions more likely to be multilocular. Only 5{\%} of the tumors were associated with an unerupted tooth. Conclusions: Odontogenic myxoma has a variable clinical and radiological appearance and it should be considered in the differential diagnosis of radiolucent and mixed radiolucent-radiopaque lesions of both jaws in all age groups.},
author = {Kaffe, I and Naor, H. and Buchner, A.},
doi = {10.1038/sj.dmfr.4600261},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Kaffe, Naor, B{\"{u}}chner - 1997 - Clinical and radiological features of odontogenic myxoma of the jaws.pdf:pdf},
issn = {0250832X},
journal = {Dentomaxillofacial Radiology},
keywords = {Jaw neoplasms,Myxoma,Odontogenic tumors,Radiography},
number = {5},
pages = {299--303},
pmid = {9482003},
title = {{Clinical and radiological features of odontogenic myxoma of the jaws}},
volume = {26},
year = {1997}
}
@article{Chi2010,
author = {Chi, Angela C. and Mapes, Ian L. and Javed, Tariq and Neville, Brad W.},
doi = {10.1016/j.joms.2009.04.120},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Chi et al. - 2010 - Epidermal Choristoma of the Oral Cavity Report of 2 Cases of an Extremely Rare Entity.pdf:pdf},
issn = {02782391},
journal = {Journal of Oral and Maxillofacial Surgery},
month = {feb},
number = {2},
pages = {451--455},
pmid = {20116722},
title = {{Epidermal Choristoma of the Oral Cavity: Report of 2 Cases of an Extremely Rare Entity}},
volume = {68},
year = {2010}
}
@article{Huang2020a,
abstract = {Recent advances in kernel-based Deep Learning models have introduced a new era in medical research. Originally designed for pattern recognition and image processing, Deep Learning models are now applied to survival prognosis of cancer patients. Specifically, Deep Learning versions of the Cox proportional hazards models are trained with transcriptomic data to predict survival outcomes in cancer patients.},
annote = {https://portal.futuresystems.org/taxonomy/term/728

the use of Deep-Learning Cox models was pioneered by Ching et al. [18], who applied Cox regression with neural networks (Cox-nnet) to predict survival using transcriptomic data became prevalent. Similarly, Katzman et al. [19] used DeepSurv with multi-layer neural networks for survival prognosis and developed a personalized treatment recommendation system.},
author = {Huang, Zhi and Johnson, Travis S and Han, Zhi and Helm, Bryan and Cao, Sha and Zhang, Chi and Salama, Paul and Rizkalla, Maher and Yu, Christina Y and Cheng, Jun and Xiang, Shunian and Zhan, Xiaohui and Zhang, Jie and Huang, Kun},
doi = {10.1186/s12920-020-0686-1},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Huang et al. - 2020 - Deep learning-based cancer survival prognosis from RNA-seq data approaches and evaluations.pdf:pdf},
issn = {1755-8794},
journal = {BMC Medical Genomics},
keywords = {AECOX,Cox-nnet,DeepSurv},
mendeley-tags = {AECOX,Cox-nnet,DeepSurv},
number = {5},
pages = {41},
title = {{Deep learning-based cancer survival prognosis from RNA-seq data: approaches and evaluations}},
url = {https://doi.org/10.1186/s12920-020-0686-1 https://bmcmedgenomics.biomedcentral.com/articles/10.1186/s12920-020-0686-1{\#}citeas},
volume = {13},
year = {2020}
}
@article{Sun2019,
abstract = {Breast cancer is a highly aggressive type of cancer with very low median survival. Accurate prognosis prediction of breast cancer can spare a significant number of patients from receiving unnecessary adjuvant systemic treatment and its related expensive medical costs. Previous work relies mostly on selected gene expression data to create a predictive model. The emergence of deep learning methods and multi-dimensional data offers opportunities for more comprehensive analysis of the molecular characteristics of breast cancer and therefore can improve diagnosis, treatment, and prevention. In this study, we propose a Multimodal Deep Neural Network by integrating Multi-dimensional Data (MDNNMD) for the prognosis prediction of breast cancer. The novelty of the method lies in the design of our method's architecture and the fusion of multi-dimensional data. The comprehensive performance evaluation results show that the proposed method achieves a better performance than the prediction methods with single-dimensional data and other existing approaches. The source code implemented by TensorFlow 1.0 deep learning library can be downloaded from the Github: https://github.com/USTC-HIlab/MDNNMD.},
author = {Sun, D and Wang, M and Li, A},
doi = {10.1109/TCBB.2018.2806438},
file = {:Users/texchi/Downloads/sun2018.pdf:pdf},
issn = {1557-9964 VO - 16},
journal = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
keywords = {Breast cancer,Breast cancer prognosis prediction,Feature extraction,Gene expression,MDNNMD,Machine learning,Neural networks,Prognostics and health management,TensorFlow 1.0 deep learning library,bioinformatics,cancer,deep learning,feature extraction,gene expression data,genetics,human breast cancer prognosis prediction,learning (artificial intelligence),molecular biophysics,molecular characteristics,multi-dimensional data,multimodal deep neural network,multimodal deep neural network by integrating mult,neural nets,patient treatment,predictive model,single-dimensional data,source code,survival},
mendeley-tags = {MDNNMD,deep learning,survival},
number = {3},
pages = {841--850},
title = {{A Multimodal Deep Neural Network for Human Breast Cancer Prognosis Prediction by Integrating Multi-Dimensional Data}},
volume = {16},
year = {2019}
}
@article{Mallik2019,
abstract = {Cancer is well recognized as a complex disease with dysregulated molecular networks or modules. Graph- and rule-based analytics have been applied extensively for cancer classification as well as prognosis using large genomic and other data over the past decade. This article provides a comprehensive review of various graph- and rule-based machine learning algorithms that have been applied to numerous genomics data to determine the cancer-specific gene modules, identify gene signature-based classifiers and carry out other related objectives of potential therapeutic value. This review focuses mainly on the methodological design and features of these algorithms to facilitate the application of these graph- and rule-based analytical approaches for cancer classification and prognosis. Based on the type of data integration, we divided all the algorithms into three categories: model-based integration, pre-processing integration and post-processing integration. Each category is further divided into four sub-categories (supervised, unsupervised, semi-supervised and survival-driven learning analyses) based on learning style. Therefore, a total of 11 categories of methods are summarized with their inputs, objectives and description, advantages and potential limitations. Next, we briefly demonstrate well-known and most recently developed algorithms for each sub-category along with salient information, such as data profiles, statistical or feature selection methods and outputs. Finally, we summarize the appropriate use and efficiency of all categories of graph- and rule mining-based learning methods when input data and specific objective are given. This review aims to help readers to select and use the appropriate algorithms for cancer classification and prognosis study.},
annote = {好複雜啊 review

CoxPath [123] and MKGI [124].

123. Mankoo PK, Shen R, Schultz N, et al. Time to recurrence and survival in serous ovarian tumors predicted from inte- grated genomic profiles. PLoS One 2011;6:e24709.
124. Kim D, Li R, Lucas A, et al. Using knowledge-driven genomic interactions for multi-omics data analysis: metadimensional models for predicting clinical outcomes in ovarian carcinoma. J Am Med Inform Assoc 2016;24: 577–587.},
author = {Mallik, Saurav and Zhao, Zhongming},
doi = {10.1093/bib/bby120},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Mallik, Zhao - 2019 - Graph- And rule-based learning algorithms A comprehensive review of their applications for cancer type classificat.pdf:pdf},
issn = {14774054},
journal = {Briefings in Bioinformatics},
keywords = {association rule mining,cancer classification,cancer prognosis,data set integration,gene signature,graph mining,learning technique},
month = {jan},
number = {1},
pages = {221--247},
pmid = {30649169},
publisher = {Oxford University Press},
title = {{Graph- And rule-based learning algorithms: A comprehensive review of their applications for cancer type classification and prognosis using genomic data}},
volume = {21},
year = {2019}
}
@article{Bhinder2020,
abstract = {The remarkable success of cancer immunotherapies, especially the checkpoint blocking antibodies, in a subset of patients has reinvigorated the study of tumor-immune crosstalk and its role in heterogeneity of response. High-throughput sequencing and imaging technologies can help recapitulate various aspects of the tumor ecosystem. Computational approaches provide an arsenal of tools to efficiently analyze, quantify and integrate multiple parameters of tumor immunity mined from these diverse but complementary high-throughput datasets. This chapter describes numerous such computational approaches in tumor immunology that leverage high-throughput data from diverse sources (genomic, transcriptomics, epigenomics and digitized histopathology images) to systematically interrogate tumor immunity in context of its microenvironment, and to identify mechanisms that confer resistance or sensitivity to cancer therapies, in particular immunotherapy.},
author = {Bhinder, Bhavneet and Elemento, Olivier},
doi = {10.1016/bs.mie.2020.01.001},
file = {:Users/texchi/Downloads/bhinder2020.pdf:pdf},
issn = {1557-7988 (Electronic)},
journal = {Methods in enzymology},
keywords = {Checkpoint blockingDeconvolutionDeep learningImmun},
language = {eng},
pages = {209--259},
pmid = {32178820},
title = {{Computational methods in tumor immunology.}},
volume = {636},
year = {2020}
}
@article{Lee2020a,
abstract = {Currently available risk prediction methods are limited in their ability to deal with complex, heterogeneous, and longitudinal data such as that available in primary care records, or in their ability to deal with multiple competing risks. This paper develops a novel deep learning approach that is able to successfully address current limitations of standard statistical approaches such as landmarking and joint modeling. Our approach, which we call Dynamic-DeepHit, flexibly incorporates the available longitudinal data comprising various repeated measurements (rather than only the last available measurements) in order to issue dynamically updated survival predictions for one or multiple competing risk(s). Dynamic-DeepHit learns the time-to-event distributions without the need to make any assumptions about the underlying stochastic models for the longitudinal and the time-to-event processes. Thus, unlike existing works in statistics, our method is able to learn data-driven associations between the longitudinal data and the various associated risks without underlying model specifications. We demonstrate the power of our approach by applying it to a real-world longitudinal dataset from the U.K. Cystic Fibrosis Registry, which includes a heterogeneous cohort of 5883 adult patients with annual follow-ups between 2009 to 2015. The results show that Dynamic-DeepHit provides a drastic improvement in discriminating individual risks of different forms of failures due to cystic fibrosis. Furthermore, our analysis utilizes post-processing statistics that provide clinical insight by measuring the influence of each covariate on risk predictions and the temporal importance of longitudinal measurements, thereby enabling us to identify covariates that are influential for different competing risks.},
annote = {xx http://www.vanderschaar-lab.com/NewWebsite/CF{\_}Changhee{\_}TBME{\_}demonstrator.html
https://bitbucket.org/mvdschaar/mlforhealthlabpub/src/master/README.md


Machine learning, however, can accurately model survival of patients in such a highly heterogeneous cohort, while treating CVD and cancer as competing risks. We have demonstrated this our lab's own survival models for competing risks, DeepHit and Dynamic-DeepHit, which offer personalized actionable prognoses that clinicians can use to design personalized treatment plans. Experiments on real-world data have demonstrated that our models outperform state-of-the-art survival models.

2021 https://hpc.nih.gov/apps/DeepHit.html},
author = {Lee, Changhee and Yoon, Jinsung and van der Schaar, Mihaela},
doi = {10.1109/TBME.2019.2909027},
file = {:Users/texchi/Downloads/lee2019.pdf:pdf},
issn = {1558-2531 (Electronic)},
journal = {IEEE transactions on bio-medical engineering},
keywords = {DeepHit,censoring,deep learning,survival,time-to-event},
language = {eng},
mendeley-tags = {DeepHit,censoring,deep learning,survival,time-to-event},
month = {jan},
number = {1},
pages = {122--133},
pmid = {30951460},
title = {{Dynamic-DeepHit: A Deep Learning Approach for Dynamic Survival Analysis With Competing Risks Based on Longitudinal Data.}},
volume = {67},
year = {2020}
}
@article{Chaudhary2018,
abstract = {Identifying robust survival subgroups of hepatocellular carcinoma (HCC) will significantly improve patient care. Currently, endeavor of integrating multi-omics data to explicitly predict HCC survival from multiple patient cohorts is lacking. To fill this gap, we present a deep learning (DL)–based model on HCC that robustly differentiates survival subpopulations of patients in six cohorts. We built the DL-based, survival-sensitive model on 360 HCC patients' data using RNA sequencing (RNA-Seq), miRNA sequencing (miRNA-Seq), and methylation data from The Cancer Genome Atlas (TCGA), which predicts prognosis as good as an alternative model where genomics and clinical data are both considered. This DL-based model provides two optimal subgroups of patients with significant survival differences (P ¼ 7.13e6) and good model fitness [concordance index (C-index) ¼ 0.68]. More aggressive subtype is associated with frequent TP53 inactivation mutations, higher expression of stemness markers (KRT19 and EPCAM) and tumor marker BIRC5, and activated Wnt and Akt signaling pathways. We validated this multi-omics model on five external datasets of various omics types: LIRI-JP cohort (n ¼ 230, C-index ¼ 0.75), NCI cohort (n ¼ 221, C-index ¼ 0.67), Chinese cohort (n ¼ 166, C-index ¼ 0.69), E-TABM-36 cohort (n ¼ 40, C-index ¼ 0.77), and Hawaiian cohort (n ¼ 27, C-index ¼ 0.82). This is the first study to employ DL to identify multi-omics features linked to the differential survival of patients with HCC. Given its robustness over multiple cohorts, we expect this workflow to be useful at predicting HCC prognosis prediction.},
annote = {other: Chai  
H, 
Zhou  
X, 
Cui  
Z, et al.  
Integrating multi-omics data with deep learning for predicting cancer prognosis. 
bioRxiv 
2019. https://www.biorxiv.org/content/10.1101/807214v1 
(15 June 2020, date last accessed).},
author = {Chaudhary, Kumardeep and Poirion, Olivier B. and Lu, Liangqun and Garmire, Lana X.},
doi = {10.1158/1078-0432.CCR-17-0853},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Chaudhary et al. - 2018 - Deep learning–based multi-omics integration robustly predicts survival in liver cancer.pdf:pdf},
issn = {15573265},
journal = {Clinical Cancer Research},
keywords = {Survival,deep learning,multi-omics},
mendeley-tags = {Survival,deep learning,multi-omics},
month = {mar},
number = {6},
pages = {1248--1259},
pmid = {28982688},
publisher = {American Association for Cancer Research Inc.},
title = {{Deep learning–based multi-omics integration robustly predicts survival in liver cancer}},
volume = {24},
year = {2018}
}
@article{Cheerla2019,
abstract = {MOTIVATION: Estimating the future course of patients with cancer lesions is invaluable to physicians; however, current clinical methods fail to effectively use the vast amount of multimodal data that is available for cancer patients. To tackle this problem, we constructed a multimodal neural network-based model to predict the survival of patients for 20 different cancer types using clinical data, mRNA expression data, microRNA expression data and histopathology whole slide images (WSIs). We developed an unsupervised encoder to compress these four data modalities into a single feature vector for each patient, handling missing data through a resilient, multimodal dropout method. Encoding methods were tailored to each data type-using deep highway networks to extract features from clinical and genomic data, and convolutional neural networks to extract features from WSIs. RESULTS: We used pancancer data to train these feature encodings and predict single cancer and pancancer overall survival, achieving a C-index of 0.78 overall. This work shows that it is possible to build a pancancer model for prognosis that also predicts prognosis in single cancer sites. Furthermore, our model handles multiple data modalities, efficiently analyzes WSIs and represents patient multimodal data flexibly into an unsupervised, informative representation. We thus present a powerful automated tool to accurately determine prognosis, a key step towards personalized treatment for cancer patients. AVAILABILITY AND IMPLEMENTATION: https://github.com/gevaertlab/MultimodalPrognosis.},
annote = {https://github.com/gevaertlab/MultimodalPrognosis

deep highway networks to extract features from clinical and genomic data

convolutional neural networks to extract features from whole slide images},
author = {Cheerla, Anika and Gevaert, Olivier},
doi = {10.1093/bioinformatics/btz342},
issn = {1367-4811 (Electronic)},
journal = {Bioinformatics (Oxford, England)},
keywords = {Computer,Deep Learning,Genome,Humans,MultimodalPrognosis,Neoplasms,Neural Networks,genetics},
language = {eng},
mendeley-tags = {MultimodalPrognosis},
month = {jul},
number = {14},
pages = {i446--i454},
pmid = {31510656},
title = {{Deep learning with multimodal representation for pancancer prognosis prediction.}},
url = {https://academic.oup.com/bioinformatics/article/35/14/i446/5529139},
volume = {35},
year = {2019}
}
